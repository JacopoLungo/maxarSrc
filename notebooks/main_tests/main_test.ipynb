{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import rasterio\n",
    "from pathlib import Path\n",
    "import os\n",
    "import reverse_geocoder as rg\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "import sys\n",
    "\n",
    "if Path.cwd().name != 'src':\n",
    "    os.chdir('/home/vaschetti/maxarSrc/src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all the events' name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 southafrica-flooding22\n",
      "1 Kalehe-DRC-Flooding-5-8-23\n",
      "2 shovi-georgia-landslide-8Aug23\n",
      "3 Emilia-Romagna-Italy-flooding-may23\n",
      "4 NWT-Canada-Aug-23\n",
      "5 Libya-Floods-Sept-2023\n",
      "6 Gambia-flooding-8-11-2022\n",
      "7 New-Zealand-Flooding23\n",
      "8 Hurricane-Fiona-9-19-2022\n",
      "9 Hurricane-Idalia-Florida-Aug23\n",
      "10 Hurricane-Ian-9-26-2022\n",
      "11 yellowstone-flooding22\n",
      "12 pakistan-flooding22\n",
      "13 Morocco-Earthquake-Sept-2023\n",
      "14 Indonesia-Earthquake22\n",
      "15 cyclone-emnati22\n",
      "16 Kahramanmaras-turkey-earthquake-23\n",
      "17 Marshall-Fire-21-Update\n",
      "18 India-Floods-Oct-2023\n",
      "19 Maui-Hawaii-fires-Aug-23\n",
      "20 tonga-volcano21\n",
      "21 BayofBengal-Cyclone-Mocha-May-23\n",
      "22 Sudan-flooding-8-22-2022\n"
     ]
    }
   ],
   "source": [
    "from my_functions.assemble import names\n",
    "events_names = names.get_all_events()\n",
    "for i, e_n in enumerate(events_names):\n",
    "    print(i, e_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set some parameters** used in the segmentation phase, such as batch size and device. </br>\n",
    "Also it instantiate both the **GroundingDino** model and the **Efficent SAM** model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaschetti/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n",
      "- GD model device: cuda:0\n",
      "- Efficient SAM device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from my_functions.configs import SegmentConfig\n",
    "batch_size = 2\n",
    "config = SegmentConfig(batch_size = batch_size, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build an Event (e.g. 'Gambia-flooding-8-11-2022')</br>\n",
    "Print its region and the names of its mosaics</br>\n",
    "Print the number of tiles contained in the first mosaic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AfricaWest-Full\n",
      "['10300100CFC9A500', '105001002BD68F00', '1040010073D77D00']\n",
      "Number of tiles: 18\n"
     ]
    }
   ],
   "source": [
    "from my_functions.assemble import holders\n",
    "\n",
    "evento = holders.Event(events_names[6], seg_config = config, when='pre')\n",
    "print(evento.region_name)\n",
    "\n",
    "all_mosaics_names = evento.all_mosaics_names\n",
    "print(all_mosaics_names)\n",
    "\n",
    "m0 = evento.mosaics[all_mosaics_names[0]]\n",
    "print(f'Number of tiles: {m0.tiles_num}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the geodataframe of the **building** of the first mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 links matching: [33303200, 3330320, 333032]\n"
     ]
    }
   ],
   "source": [
    "m0.set_build_gdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the geodataframe of the **roads** of the first mosaic..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not USA. Region name: AfricaWest-Full.tsv\n"
     ]
    }
   ],
   "source": [
    "m0.set_road_gdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and project it in the right coord system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158659</th>\n",
       "      <td>GMB</td>\n",
       "      <td>LINESTRING (317880.927 1483236.891, 317881.884...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158664</th>\n",
       "      <td>GMB</td>\n",
       "      <td>LINESTRING (317732.453 1489568.084, 317792.204...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158669</th>\n",
       "      <td>GMB</td>\n",
       "      <td>LINESTRING (316249.801 1478543.584, 316213.663...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158689</th>\n",
       "      <td>GMB</td>\n",
       "      <td>LINESTRING (317326.052 1486717.098, 317338.950...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158694</th>\n",
       "      <td>GMB</td>\n",
       "      <td>LINESTRING (317846.778 1481976.223, 317849.189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504425</th>\n",
       "      <td>GMB</td>\n",
       "      <td>LINESTRING (316329.842 1477672.263, 316261.217...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504460</th>\n",
       "      <td>GMB</td>\n",
       "      <td>LINESTRING (316419.470 1482442.080, 316398.261...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504480</th>\n",
       "      <td>GMB</td>\n",
       "      <td>LINESTRING (320392.218 1489136.742, 320505.915...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504485</th>\n",
       "      <td>GMB</td>\n",
       "      <td>LINESTRING (316436.428 1478302.096, 316568.703...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504495</th>\n",
       "      <td>GMB</td>\n",
       "      <td>LINESTRING (315294.778 1483308.900, 315297.682...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18325 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       country                                           geometry\n",
       "158659     GMB  LINESTRING (317880.927 1483236.891, 317881.884...\n",
       "158664     GMB  LINESTRING (317732.453 1489568.084, 317792.204...\n",
       "158669     GMB  LINESTRING (316249.801 1478543.584, 316213.663...\n",
       "158689     GMB  LINESTRING (317326.052 1486717.098, 317338.950...\n",
       "158694     GMB  LINESTRING (317846.778 1481976.223, 317849.189...\n",
       "...        ...                                                ...\n",
       "504425     GMB  LINESTRING (316329.842 1477672.263, 316261.217...\n",
       "504460     GMB  LINESTRING (316419.470 1482442.080, 316398.261...\n",
       "504480     GMB  LINESTRING (320392.218 1489136.742, 320505.915...\n",
       "504485     GMB  LINESTRING (316436.428 1478302.096, 316568.703...\n",
       "504495     GMB  LINESTRING (315294.778 1483308.900, 315297.682...\n",
       "\n",
       "[18325 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m0.proj_road_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/data2/vaschetti_data/maxar/Gambia-flooding-8-11-2022/pre/10300100CFC9A500/033133031233.tif')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m0.tiles_paths[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchgeo.datasets import stack_samples, unbind_samples\n",
    "from torch.utils.data import DataLoader\n",
    "from rasterio.windows import Window\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from time import time\n",
    "import warnings\n",
    "import rasterio\n",
    "import torch\n",
    "\n",
    "from my_functions.samplers import samplers, samplers_utils\n",
    "from my_functions.geo_datasets import geoDatasets\n",
    "from my_functions.ESAM_segment import segment, segment_utils\n",
    "from my_functions.detect import detect\n",
    "\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1682 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sampler\n",
      "tile_polygon:  POLYGON ((315427.24609375 1485156.25, 320156.25 1485156.25, 320156.25 1479843.75, 315394.8974609375 1479843.75, 315427.24609375 1485156.25))\n",
      "\n",
      "__________________________\n",
      "Batch number:  1\n",
      "Num detections in batch: [ 51 102]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1682 [00:06<3:04:08,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "__________________________\n",
      "Batch number:  2\n",
      "Num detections in batch: [78 45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1682 [00:08<3:54:54,  8.38s/it]\n"
     ]
    }
   ],
   "source": [
    "#Top, working\n",
    "\n",
    "self = m0\n",
    "tile_path = m0.tiles_paths[17]\n",
    "\n",
    "seg_config = self.event.seg_config\n",
    "dataset = geoDatasets.Maxar(str(tile_path))\n",
    "sampler = samplers.MyBatchGridGeoSampler(dataset, batch_size=seg_config.batch_size, size=seg_config.size, stride=seg_config.stride)\n",
    "dataloader = DataLoader(dataset , batch_sampler=sampler, collate_fn=stack_samples)\n",
    "\n",
    "canvas = np.zeros((seg_config.size, seg_config.size, 3), dtype=np.uint8)\n",
    "i = 0\n",
    "f_i = 2\n",
    "for batch in tqdm(dataloader):\n",
    "    i+=1\n",
    "    \"\"\"if i != f_i:\n",
    "        i+=1\n",
    "        continue\"\"\"\n",
    "    original_img_tsr = batch['image']\n",
    "    img_b = batch['image'].permute(0,2,3,1).numpy().astype('uint8') #TODO: l'immagine viene convertita in numpy ma magari è meglio lasciarla in tensor\n",
    "    \n",
    "    #get the tree boxes in batches and the number of trees for each image\n",
    "    tree_boxes_b, num_trees4img = detect.get_GD_boxes(img_b, seg_config.GD_model,\n",
    "                                        seg_config.TEXT_PROMPT,\n",
    "                                        seg_config.BOX_THRESHOLD,\n",
    "                                        seg_config.TEXT_THRESHOLD,\n",
    "                                        dataset.res,\n",
    "                                        device = seg_config.device,\n",
    "                                        max_area_mt2 = seg_config.max_area_GD_boxes_mt2)\n",
    "    \n",
    "    #get the building boxes in batches and the number of buildings for each image\n",
    "    building_boxes_b, num_build4img = detect.get_batch_buildings_boxes(batch['bbox'],\n",
    "                                                                proj_buildings_gdf = self.proj_build_gdf,\n",
    "                                                                dataset_res = dataset.res,\n",
    "                                                                ext_mt = 10)\n",
    "    max_detect = max(num_trees4img + num_build4img)\n",
    "    print(\"\\n__________________________\")\n",
    "    print(\"Batch number: \", i)\n",
    "    print(f'Num detections in batch: {num_trees4img + num_build4img}')\n",
    "    \n",
    "    #obtain the right input for the ESAM model (trees + buildings)\n",
    "    input_points, input_labels = segment_utils.get_input_pts_and_lbs(tree_boxes_b, building_boxes_b, max_detect)\n",
    "    \n",
    "    # segment the image and get for each image as many masks as the number of boxes,\n",
    "    # for GPU constraint use num_parall_queries\n",
    "    all_masks_b = segment.ESAM_from_inputs(original_img_tsr,\n",
    "                                            torch.from_numpy(input_points),\n",
    "                                            torch.from_numpy(input_labels),\n",
    "                                            efficient_sam = seg_config.efficient_sam,\n",
    "                                            device = seg_config.device,\n",
    "                                            num_parall_queries = 5)\n",
    "    \n",
    "    #for each image, discern the masks in trees, buildings and padding\n",
    "    tree_mask_b, building_mask_b, pad_mask_b = segment_utils.discern(all_masks_b, num_trees4img, num_build4img)\n",
    "    \n",
    "    if i == f_i:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_functions import plotting_utils as plu\n",
    "\n",
    "ix = 1\n",
    "plu.plot_comparison(img_b[ix], np.stack((tree_mask_b[ix], building_mask_b[ix])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_canvas(canvas: np.array,\n",
    "                 patch_masks_b: np.array,\n",
    "                 img_ixs: np.array,\n",
    "                 stride: int,\n",
    "                 total_cols: int):\n",
    "    \"\"\"\n",
    "    Write the patmasks in the canvas\n",
    "    Inputs:\n",
    "        canvas: np.array of shape (channel, h_tile, w_tile)\n",
    "        patch_masks_b: np.array of shape (b, channel, h_patch, w_patch)\n",
    "        img_ixs: np.array of shape (b,)\n",
    "    \"\"\"\n",
    "    size = patch_masks_b.shape[-1]\n",
    "    #print(\"img_ixs\", img_ixs)\n",
    "    for img_ix, patch_mask in zip(img_ixs, patch_masks_b):\n",
    "        rows_changed = img_ix // total_cols\n",
    "        cols_changed = img_ix % total_cols\n",
    "        inv_base = (canvas.shape[1] - 1 - size) - (stride * rows_changed)\n",
    "        base = (stride * cols_changed)\n",
    "        canva_writable_space = canvas[:, inv_base: inv_base + size, base: base + size].shape[1:] #useful when reached the border of the canva\n",
    "        print('\\nparte di canva', canvas[:, inv_base: inv_base + size, base: base + size].shape)\n",
    "        print('patch', patch_mask[:, :canva_writable_space[0], :canva_writable_space[1]].shape)\n",
    "        canvas[:, inv_base: inv_base + size, base: base + size] = patch_mask[:, :canva_writable_space[0], :canva_writable_space[1]]\n",
    "\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1682 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sampler\n",
      "tile_polygon:  POLYGON ((315427.24609375 1485156.25, 320156.25 1485156.25, 320156.25 1479843.75, 315394.8974609375 1479843.75, 315427.24609375 1485156.25))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1682 [00:00<15:44,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD_time:  0.5186784267425537\n",
      "\n",
      "__________________________\n",
      "Batch number:  1\n",
      "Num detections in batch per img: [0 0]\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1682 [00:01<16:28,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD_time:  0.5701959133148193\n",
      "\n",
      "__________________________\n",
      "Batch number:  2\n",
      "Num detections in batch per img: [0 0]\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.5595622062683105\n",
      "\n",
      "__________________________\n",
      "Batch number:  3\n",
      "Num detections in batch per img: [ 6 51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1682 [00:02<28:01,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.488964319229126\n",
      "\n",
      "__________________________\n",
      "Batch number:  4\n",
      "Num detections in batch per img: [102  78]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1682 [00:05<44:16,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.4842491149902344\n",
      "\n",
      "__________________________\n",
      "Batch number:  5\n",
      "Num detections in batch per img: [45 29]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1682 [00:06<41:15,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.48392653465270996\n",
      "\n",
      "__________________________\n",
      "Batch number:  6\n",
      "Num detections in batch per img: [54 78]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/1682 [00:08<44:48,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.48981475830078125\n",
      "\n",
      "__________________________\n",
      "Batch number:  7\n",
      "Num detections in batch per img: [90 83]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/1682 [00:10<51:08,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.4922783374786377\n",
      "\n",
      "__________________________\n",
      "Batch number:  8\n",
      "Num detections in batch per img: [78 73]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/1682 [00:12<51:26,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.48270153999328613\n",
      "\n",
      "__________________________\n",
      "Batch number:  9\n",
      "Num detections in batch per img: [81 67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1682 [00:14<54:23,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.5176615715026855\n",
      "\n",
      "__________________________\n",
      "Batch number:  10\n",
      "Num detections in batch per img: [32 22]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1682 [00:15<47:07,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.4971582889556885\n",
      "\n",
      "__________________________\n",
      "Batch number:  11\n",
      "Num detections in batch per img: [37 60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1682 [00:17<45:37,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.48652124404907227\n",
      "\n",
      "__________________________\n",
      "Batch number:  12\n",
      "Num detections in batch per img: [64 76]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1682 [00:19<48:38,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.48552989959716797\n",
      "\n",
      "__________________________\n",
      "Batch number:  13\n",
      "Num detections in batch per img: [ 97 119]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/1682 [00:22<58:37,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.4897136688232422\n",
      "\n",
      "__________________________\n",
      "Batch number:  14\n",
      "Num detections in batch per img: [111 104]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/1682 [00:24<1:04:15,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.48824167251586914\n",
      "\n",
      "__________________________\n",
      "Batch number:  15\n",
      "Num detections in batch per img: [119 144]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/1682 [00:28<1:16:12,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.48972296714782715\n",
      "\n",
      "__________________________\n",
      "Batch number:  16\n",
      "Num detections in batch per img: [146 152]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/1682 [00:32<1:27:39,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.490833044052124\n",
      "\n",
      "__________________________\n",
      "Batch number:  17\n",
      "Num detections in batch per img: [162 132]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/1682 [00:37<1:39:07,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.4985954761505127\n",
      "\n",
      "__________________________\n",
      "Batch number:  18\n",
      "Num detections in batch per img: [126 168]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/1682 [00:42<1:48:18,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.4842205047607422\n",
      "\n",
      "__________________________\n",
      "Batch number:  19\n",
      "Num detections in batch per img: [177 134]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/1682 [00:46<1:56:51,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.48509645462036133\n",
      "\n",
      "__________________________\n",
      "Batch number:  20\n",
      "Num detections in batch per img: [141 113]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/1682 [00:50<1:53:32,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.4893667697906494\n",
      "\n",
      "__________________________\n",
      "Batch number:  21\n",
      "Num detections in batch per img: [121 130]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/1682 [00:54<1:47:15,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.49751949310302734\n",
      "\n",
      "__________________________\n",
      "Batch number:  22\n",
      "Num detections in batch per img: [105  77]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 22/1682 [00:56<1:36:54,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.48704004287719727\n",
      "\n",
      "__________________________\n",
      "Batch number:  23\n",
      "Num detections in batch per img: [83 60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 23/1682 [00:58<1:24:53,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.4972820281982422\n",
      "\n",
      "__________________________\n",
      "Batch number:  24\n",
      "Num detections in batch per img: [48 72]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 24/1682 [01:00<1:14:36,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.5061535835266113\n",
      "\n",
      "__________________________\n",
      "Batch number:  25\n",
      "Num detections in batch per img: [112 127]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 25/1682 [01:04<1:19:58,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.4856555461883545\n",
      "\n",
      "__________________________\n",
      "Batch number:  26\n",
      "Num detections in batch per img: [145 169]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 26/1682 [01:08<1:35:14,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.48273801803588867\n",
      "\n",
      "__________________________\n",
      "Batch number:  27\n",
      "Num detections in batch per img: [152 156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 27/1682 [01:13<1:41:42,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.481931209564209\n",
      "\n",
      "__________________________\n",
      "Batch number:  28\n",
      "Num detections in batch per img: [142 119]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 28/1682 [01:16<1:42:26,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.5005137920379639\n",
      "\n",
      "__________________________\n",
      "Batch number:  29\n",
      "Num detections in batch per img: [100  55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 29/1682 [01:19<1:32:11,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 308)\n",
      "patch (3, 600, 308)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 30/1682 [01:19<1:08:46,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD_time:  0.49041032791137695\n",
      "\n",
      "__________________________\n",
      "Batch number:  30\n",
      "Num detections in batch per img: [0 0]\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 31/1682 [01:20<53:07,  1.93s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD_time:  0.5890471935272217\n",
      "\n",
      "__________________________\n",
      "Batch number:  31\n",
      "Num detections in batch per img: [0 0]\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.5934374332427979\n",
      "\n",
      "__________________________\n",
      "Batch number:  32\n",
      "Num detections in batch per img: [ 6 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 32/1682 [01:21<48:03,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.4880220890045166\n",
      "\n",
      "__________________________\n",
      "Batch number:  33\n",
      "Num detections in batch per img: [86 80]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 33/1682 [01:23<51:57,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.48785996437072754\n",
      "\n",
      "__________________________\n",
      "Batch number:  34\n",
      "Num detections in batch per img: [52 45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 34/1682 [01:25<47:49,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.48991918563842773\n",
      "\n",
      "__________________________\n",
      "Batch number:  35\n",
      "Num detections in batch per img: [70 88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 35/1682 [01:27<51:32,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.5104312896728516\n",
      "\n",
      "__________________________\n",
      "Batch number:  36\n",
      "Num detections in batch per img: [84 63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 36/1682 [01:29<53:14,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.4903564453125\n",
      "\n",
      "__________________________\n",
      "Batch number:  37\n",
      "Num detections in batch per img: [54 58]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 37/1682 [01:31<49:39,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.4880964756011963\n",
      "\n",
      "__________________________\n",
      "Batch number:  38\n",
      "Num detections in batch per img: [66 63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 38/1682 [01:32<48:46,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.49414515495300293\n",
      "\n",
      "__________________________\n",
      "Batch number:  39\n",
      "Num detections in batch per img: [20  1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 39/1682 [01:33<41:41,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.5052666664123535\n",
      "\n",
      "__________________________\n",
      "Batch number:  40\n",
      "Num detections in batch per img: [15 58]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 40/1682 [01:35<42:10,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.4941251277923584\n",
      "\n",
      "__________________________\n",
      "Batch number:  41\n",
      "Num detections in batch per img: [69 57]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 41/1682 [01:37<43:33,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.4863715171813965\n",
      "\n",
      "__________________________\n",
      "Batch number:  42\n",
      "Num detections in batch per img: [ 73 108]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 42/1682 [01:39<52:45,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.4922828674316406\n",
      "\n",
      "__________________________\n",
      "Batch number:  43\n",
      "Num detections in batch per img: [98 84]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 43/1682 [01:42<56:49,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.5114972591400146\n",
      "\n",
      "__________________________\n",
      "Batch number:  44\n",
      "Num detections in batch per img: [97 96]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 44/1682 [01:44<59:51,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.4983181953430176\n",
      "\n",
      "__________________________\n",
      "Batch number:  45\n",
      "Num detections in batch per img: [105 127]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 45/1682 [01:47<1:08:52,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.5000081062316895\n",
      "\n",
      "__________________________\n",
      "Batch number:  46\n",
      "Num detections in batch per img: [139 143]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 46/1682 [01:51<1:19:19,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.5055358409881592\n",
      "\n",
      "__________________________\n",
      "Batch number:  47\n",
      "Num detections in batch per img: [133 139]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 47/1682 [01:55<1:24:52,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.48621392250061035\n",
      "\n",
      "__________________________\n",
      "Batch number:  48\n",
      "Num detections in batch per img: [131 130]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 48/1682 [01:58<1:27:25,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.4966580867767334\n",
      "\n",
      "__________________________\n",
      "Batch number:  49\n",
      "Num detections in batch per img: [140 120]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 49/1682 [02:02<1:30:39,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "GD_time:  0.4962198734283447\n",
      "\n",
      "__________________________\n",
      "Batch number:  50\n",
      "Num detections in batch per img: [140 142]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 49/1682 [02:06<1:10:06,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "parte di canva (3, 600, 600)\n",
      "patch (3, 600, 600)\n",
      "\n",
      "Total Time for 100 images:  126.22936868667603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def segment_tile(self, tile_path):\n",
    "    seg_config = self.event.seg_config\n",
    "\n",
    "    dataset = geoDatasets.MxrSingleTile(str(tile_path))\n",
    "    sampler = samplers.WholeTifGridGeoSampler(dataset, batch_size=seg_config.batch_size, size=seg_config.size, stride=seg_config.stride)\n",
    "    dataloader = DataLoader(dataset , batch_sampler=sampler, collate_fn=stack_samples)\n",
    "\n",
    "    canvas = np.zeros((3,) + samplers_utils.tile_sizes(dataset), dtype=np.uint8) #dim (3, h_tile, w_tile). The first dim is tree, build, pad\n",
    "    \n",
    "    all_batches_img_ixs = np.arange(len(sampler)).reshape((-1, batch_size))\n",
    "    _, total_cols = sampler.get_num_rows_cols()\n",
    "    \n",
    "    i = 0\n",
    "    f_i = 50\n",
    "    start_time_all = time()\n",
    "    for batch_ix, batch in tqdm(enumerate(dataloader), total = len(dataloader)):\n",
    "        i+=1\n",
    "        original_img_tsr = batch['image']\n",
    "        img_b = batch['image'].permute(0,2,3,1).numpy().astype('uint8') #TODO: l'immagine viene convertita in numpy ma magari è meglio lasciarla in tensor\n",
    "\n",
    "        #trees\n",
    "        GD_t_0 = time()\n",
    "        \n",
    "        #get the tree boxes in batches and the number of trees for each image\n",
    "        tree_boxes_b, num_trees4img = detect.get_GD_boxes(img_b,\n",
    "                                            seg_config.GD_model,\n",
    "                                            seg_config.TEXT_PROMPT,\n",
    "                                            seg_config.BOX_THRESHOLD,\n",
    "                                            seg_config.TEXT_THRESHOLD,\n",
    "                                            dataset.res,\n",
    "                                            device = seg_config.device,\n",
    "                                            max_area_mt2 = seg_config.max_area_GD_boxes_mt2)\n",
    "        #tree_boxes_b è una lista con degli array di shape (n, 4) dove n è il numero di tree boxes\n",
    "        \n",
    "        #print('GD_time: ', time() - GD_t_0)\n",
    "\n",
    "        #get the building boxes in batches and the number of buildings for each image\n",
    "        building_boxes_b, num_build4img = detect.get_batch_buildings_boxes(batch['bbox'],\n",
    "                                                                    proj_buildings_gdf = self.proj_build_gdf,\n",
    "                                                                    dataset_res = dataset.res,\n",
    "                                                                    ext_mt = 10)\n",
    "        \n",
    "        #building_boxes_b è una lista con degli array di shape (n, 4) dove n è il numero di building boxes\n",
    "        \n",
    "        max_detect = max(num_trees4img + num_build4img)\n",
    "        \n",
    "        #print(\"\\n__________________________\")\n",
    "        #print(\"Batch number: \", i)\n",
    "        #print(f'Num detections in batch per img: {num_trees4img + num_build4img}')\n",
    "        \n",
    "        #obtain the right input for the ESAM model (trees + buildings)\n",
    "        input_points, input_labels = segment_utils.get_input_pts_and_lbs(tree_boxes_b, building_boxes_b, max_detect)\n",
    "        \n",
    "        # segment the image and get for each image as many masks as the number of boxes,\n",
    "        # for GPU constraint use num_parall_queries\n",
    "        all_masks_b = segment.ESAM_from_inputs(original_img_tsr,\n",
    "                                                torch.from_numpy(input_points),\n",
    "                                                torch.from_numpy(input_labels),\n",
    "                                                efficient_sam = seg_config.efficient_sam,\n",
    "                                                device = seg_config.device,\n",
    "                                                num_parall_queries = 5)\n",
    "        \n",
    "        \n",
    "        #for each image, discern the masks in trees, buildings and padding\n",
    "        patch_masks_b = segment_utils.discern_mode(all_masks_b, num_trees4img, num_build4img, mode = 'bchw')\n",
    "        \n",
    "        canvas = write_canvas(canvas = canvas,\n",
    "                                            patch_masks_b =  patch_masks_b,\n",
    "                                            img_ixs = all_batches_img_ixs[batch_ix],\n",
    "                                            stride = seg_config.stride,\n",
    "                                            total_cols = total_cols)\n",
    "        \n",
    "        if i == f_i:\n",
    "            break\n",
    "        \n",
    "    #print(f'\\nTotal Time for {seg_config.batch_size * i} images: ', time() - start_time_all)\n",
    "    return canvas\n",
    "\n",
    "canvas = segment_tile(m0, m0.tiles_paths[17])\n",
    "#img_b, original_img, tree_boxes_b, building_boxes_b, all_masks_b, tree_mask_b, building_mask_b, pad_mask_b = segment_tile(m0, m0.tiles_paths[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbsAAAGiCAYAAAB+sGhNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAABg5klEQVR4nO3deVhV5f428O9m2oDKoAiIgqgkHEcyTkiS5SWKHMrhVBYvqXEcOZppisjPKfUqSEsrXzPtlHo6qekpB3JIQ01NJEXE2ZzlmICK7I0yw/3+wbufH0twOmHq8v5c1/dS1nr22s9ib/a9hmetbQAAISIi0jGrB90BIiKi+41hR0REusewIyIi3WPYERGR7jHsiIhI9xh2RESkeww7IiLSPYYdERHpHsOOiIh0j2FHRES698iH3fz588XX11fs7e0lODhYfvnllwfdJSIiesg80mH3zTffyNtvvy3Tpk2T/fv3S8eOHSU8PFxyc3MfdNeIiOghYniUbwQdHBwsf/7zn+X//t//KyIilZWV4u3tLW+++aZMnDjxAfeOiIgeFjYPugP/rdLSUklPT5eEhAQ1zcrKSsLCwiQ1NbXWx5SUlEhJSYn6ubKyUvLy8qRRo0ZiMBjue5+JiKjuAJCCggLx8vISK6vbH6h8ZMPuypUrUlFRIR4eHprpHh4ecvz48Vofk5iYKNOnT/8jukdERH+QrKwsadas2W3bPNLn7O5VQkKCmEwmVRcuXHjQXSIiot+pQYMGd2zzyO7Zubm5ibW1teTk5Gim5+TkiKenZ62PMRqNYjQa/4juERHRH+RuTkM9snt2dnZ28tRTT0lKSoqaVllZKSkpKRISEvIAe0ZERA+bR3bPTkTk7bfflkGDBklQUJA8/fTT8tFHH8mNGzckJibmQXeNiIgeIo902L366qty+fJlmTp1qmRnZ0tgYKBs2rSpxqAVIiJ6vD3S19n9XmazWZydnR90N4iI6HcwmUzi5OR02zaP7Dk7IiKiu8WwIyIi3WPYERGR7jHsiIhI9xh2RESkeww7IiLSPYYdERHpHsOOiIh0j2FHRES6x7AjIiLdY9gREZHuMeyIiEj3GHZERKR7DDsiItI9hh0REekew46IiHSPYUdERLrHsCMiIt1j2BERke4x7IiISPcYdkREpHsMOyIi0j2GHRER6R7DjoiIdI9hR0REusewIyIi3WPYERGR7jHsiIhI9xh2RESkeww7IiLSPYYdERHpXp2HXWJiovz5z3+WBg0aiLu7u/Tt21dOnDihaVNcXCwjR46URo0aSf369eWll16SnJwcTZsLFy5IZGSkODo6iru7u8TFxUl5ebmmzfbt26VTp05iNBrFz89PlixZUterQ0REeoA6Fh4ejsWLF+Pw4cM4cOAA/vKXv8DHxwfXr19XbUaMGAFvb2+kpKRg37596Ny5M5555hk1v7y8HO3atUNYWBgyMjKwYcMGuLm5ISEhQbU5c+YMHB0d8fbbb+Po0aOYN28erK2tsWnTprvuq8lkgoiwWCwW6xEuk8l0x8/7Og+7m+Xm5kJE8NNPPwEA8vPzYWtri1WrVqk2x44dg4ggNTUVALBhwwZYWVkhOztbtVmwYAGcnJxQUlICAJgwYQLatm2rea5XX30V4eHhd903hh2LxWI9+nU3YXffz9mZTCYREWnYsKGIiKSnp0tZWZmEhYWpNgEBAeLj4yOpqakiIpKamirt27cXDw8P1SY8PFzMZrMcOXJEtam+DEsbyzJqU1JSImazWVNERKR/9zXsKisrZcyYMdKlSxdp166diIhkZ2eLnZ2duLi4aNp6eHhIdna2alM96CzzLfNu18ZsNktRUVGt/UlMTBRnZ2dV3t7ev3sdiYjo4Xdfw27kyJFy+PBhWbFixf18mruWkJAgJpNJVVZW1oPuEhER/QFs7teCR40aJd9//73s2LFDmjVrpqZ7enpKaWmp5Ofna/bucnJyxNPTU7X55ZdfNMuzjNas3ubmEZw5OTni5OQkDg4OtfbJaDSK0Wj83etGRESPljrfswMgo0aNktWrV8vWrVulRYsWmvlPPfWU2NraSkpKipp24sQJuXDhgoSEhIiISEhIiBw6dEhyc3NVmy1btoiTk5O0adNGtam+DEsbyzKIiIiUux66eJdiY2Ph7OyM7du349KlS6oKCwtVmxEjRsDHxwdbt27Fvn37EBISgpCQEDXfculBz549ceDAAWzatAmNGzeu9dKDuLg4HDt2DPPnz+elBywWi/UY1gO59OBWnVm8eLFqU1RUhL///e9wdXWFo6Mj+vXrh0uXLmmWc+7cOURERMDBwQFubm4YN24cysrKNG22bduGwMBA2NnZoWXLlprnuBsMOxaLxXr0627CzvD/A+qxZDabxdnZ+UF3g4iIfgeTySROTk63bcN7YxIRke4x7IiISPcYdkREpHsMOyIi0j2GHRER6R7DjoiIdI9hR0REusewIyIi3WPYERGR7jHsiIhI9xh2RESkeww7IiLSPYYdERHpHsOOiIh0j2FHRES6x7AjIiLdY9gREZHuMeyIiEj3GHZERKR7DDsiItI9hh0REekew46IiHSPYUdERLrHsCMiIt1j2BERke4x7IiISPcYdkREpHsMOyIi0j2GHRER6R7DjoiIdI9hR0REusewIyIi3bvvYZeUlCQGg0HGjBmjphUXF8vIkSOlUaNGUr9+fXnppZckJydH87gLFy5IZGSkODo6iru7u8TFxUl5ebmmzfbt26VTp05iNBrFz89PlixZcr9Xh4iIHkW4j3755Rf4+vqiQ4cOeOutt9T0ESNGwNvbGykpKdi3bx86d+6MZ555Rs0vLy9Hu3btEBYWhoyMDGzYsAFubm5ISEhQbc6cOQNHR0e8/fbbOHr0KObNmwdra2ts2rTprvtnMpkgIiwWi8V6hMtkMt3x8/6+hV1BQQGeeOIJbNmyBc8995wKu/z8fNja2mLVqlWq7bFjxyAiSE1NBQBs2LABVlZWyM7OVm0WLFgAJycnlJSUAAAmTJiAtm3bap7z1VdfRXh4+F33kWHHYrFYj37dTdjdt8OYI0eOlMjISAkLC9NMT09Pl7KyMs30gIAA8fHxkdTUVBERSU1Nlfbt24uHh4dqEx4eLmazWY4cOaLa3Lzs8PBwtYzalJSUiNls1hQREemfzf1Y6IoVK2T//v2yd+/eGvOys7PFzs5OXFxcNNM9PDwkOztbtakedJb5lnm3a2M2m6WoqEgcHBxqPHdiYqJMnz79v14vIiJ6NNX5nl1WVpa89dZb8vXXX4u9vX1dL/53SUhIEJPJpCorK+tBd4mIiP4AdR526enpkpubK506dRIbGxuxsbGRn376ST755BOxsbERDw8PKS0tlfz8fM3jcnJyxNPTU0REPD09a4zOtPx8pzZOTk617tWJiBiNRnFyctIUERHpX52HXffu3eXQoUNy4MABVUFBQRIdHa3+b2trKykpKeoxJ06ckAsXLkhISIiIiISEhMihQ4ckNzdXtdmyZYs4OTlJmzZtVJvqy7C0sSyDiIhIueuhi79D9dGYQNWlBz4+Pti6dSv27duHkJAQhISEqPmWSw969uyJAwcOYNOmTWjcuHGtlx7ExcXh2LFjmD9/Pi89YLFYrMewHuilB9XdHHZFRUX4+9//DldXVzg6OqJfv364dOmS5jHnzp1DREQEHBwc4ObmhnHjxqGsrEzTZtu2bQgMDISdnR1atmyJxYsX31O/GHYsFov16NfdhJ0BAOQxZTabxdnZ+UF3g4iIfgeTyXTHMRi8NyYREekew46IiHSPYUdERLrHsCMiIt1j2BERke4x7IiISPcYdkREpHsMOyIi0j2GHRER6R7DjoiIdI9hR0REusewIyIi3WPYERGR7jHsiIhI9xh2RESkeww7IiLSPYYdERHpHsOOiIh0j2FHRES6x7AjIiLdY9gREZHuMeyIiEj3GHZERKR7DDsiItI9hh0REekew46IiHSPYUdERLrHsCMiIt1j2BERke4x7IiISPcYdkREpHv3JewuXrwor7/+ujRq1EgcHBykffv2sm/fPjUfgEydOlWaNGkiDg4OEhYWJidPntQsIy8vT6Kjo8XJyUlcXFxk8ODBcv36dU2bgwcPyrPPPiv29vbi7e0ts2bNuh+rQ0REjzrUsby8PDRv3hxvvPEG0tLScObMGfzwww84deqUapOUlARnZ2esWbMGmZmZ6N27N1q0aIGioiLVplevXujYsSP27NmDnTt3ws/PD1FRUWq+yWSCh4cHoqOjcfjwYSxfvhwODg5YuHDhXffVZDJBRFgsFov1CJfJZLrj532dh118fDxCQ0NvOb+yshKenp6YPXu2mpafnw+j0Yjly5cDAI4ePQoRwd69e1WbjRs3wmAw4OLFiwCATz/9FK6urigpKdE8t7+//133lWHHYrFYj37dTdjV+WHMdevWSVBQkLzyyivi7u4uTz75pHz++edq/tmzZyU7O1vCwsLUNGdnZwkODpbU1FQREUlNTRUXFxcJCgpSbcLCwsTKykrS0tJUm65du4qdnZ1qEx4eLidOnJBr167V2reSkhIxm82aIiIi/avzsDtz5owsWLBAnnjiCfnhhx8kNjZWRo8eLUuXLhURkezsbBER8fDw0DzOw8NDzcvOzhZ3d3fNfBsbG2nYsKGmTW3LqP4cN0tMTBRnZ2dV3t7ev3NtiYjoUVDnYVdZWSmdOnWS9957T5588kkZNmyYDB06VD777LO6fqp7lpCQICaTSVVWVtaD7hIREf0B6jzsmjRpIm3atNFM+9Of/iQXLlwQERFPT08REcnJydG0ycnJUfM8PT0lNzdXM7+8vFzy8vI0bWpbRvXnuJnRaBQnJydNERGR/tV52HXp0kVOnDihmfbrr79K8+bNRUSkRYsW4unpKSkpKWq+2WyWtLQ0CQkJERGRkJAQyc/Pl/T0dNVm69atUllZKcHBwarNjh07pKysTLXZsmWL+Pv7i6ura12vFhERPcrueujiXfrll19gY2ODd999FydPnsTXX38NR0dH/Otf/1JtkpKS4OLigrVr1+LgwYPo06dPrZcePPnkk0hLS8OuXbvwxBNPaC49yM/Ph4eHBwYMGIDDhw9jxYoVcHR05KUHLBaL9ZjVA7n0AACSk5PRrl07GI1GBAQEYNGiRZr5lZWVmDJlCjw8PGA0GtG9e3ecOHFC0+bq1auIiopC/fr14eTkhJiYGBQUFGjaZGZmIjQ0FEajEU2bNkVSUtI99ZNhx2KxWI9+3U3YGQBAHlNms1mcnZ0fdDeIiOh3MJlMdxyDwXtjEhGR7jHsiIhI9xh2RESkeww7IiLSPYYdERHpHsOOiIh0j2FHRES6x7AjIiLdY9gREZHuMeyIiEj3GHZERKR7DDsiItI9hh0REekew46IiHSPYUdERLrHsCMiIt1j2BERke4x7IiISPcYdkREpHsMOyIi0j2GHRER6R7DjoiIdI9hR0REusewIyIi3WPYERGR7jHsiIhI9xh2RESkeww7IiLSPYYdERHpHsOOiIh0j2FHRES6x7AjIiLdq/Owq6iokClTpkiLFi3EwcFBWrVqJTNnzhQAqg0AmTp1qjRp0kQcHBwkLCxMTp48qVlOXl6eREdHi5OTk7i4uMjgwYPl+vXrmjYHDx6UZ599Vuzt7cXb21tmzZpV16tDRER6gDr27rvvolGjRvj+++9x9uxZrFq1CvXr18fHH3+s2iQlJcHZ2Rlr1qxBZmYmevfujRYtWqCoqEi16dWrFzp27Ig9e/Zg586d8PPzQ1RUlJpvMpng4eGB6OhoHD58GMuXL4eDgwMWLlx41301mUwQERaLxWI9wmUyme74eV/nYRcZGYm//e1vmml//etfER0dDQCorKyEp6cnZs+erebn5+fDaDRi+fLlAICjR49CRLB3717VZuPGjTAYDLh48SIA4NNPP4WrqytKSkpUm/j4ePj7+991Xxl2LBaL9ejX3YRdnR/GfOaZZyQlJUV+/fVXERHJzMyUXbt2SUREhIiInD17VrKzsyUsLEw9xtnZWYKDgyU1NVVERFJTU8XFxUWCgoJUm7CwMLGyspK0tDTVpmvXrmJnZ6fahIeHy4kTJ+TatWu19q2kpETMZrOmiIhI/2zqeoETJ04Us9ksAQEBYm1tLRUVFfLuu+9KdHS0iIhkZ2eLiIiHh4fmcR4eHmpedna2uLu7aztqYyMNGzbUtGnRokWNZVjmubq61uhbYmKiTJ8+vQ7WkoiIHiV1vme3cuVK+frrr2XZsmWyf/9+Wbp0qXzwwQeydOnSun6qe5aQkCAmk0lVVlbWg+4SERH9Aep8zy4uLk4mTpwor732moiItG/fXs6fPy+JiYkyaNAg8fT0FBGRnJwcadKkiXpcTk6OBAYGioiIp6en5ObmapZbXl4ueXl56vGenp6Sk5OjaWP52dLmZkajUYxG4+9fSSIieqTU+Z5dYWGhWFlpF2ttbS2VlZUiItKiRQvx9PSUlJQUNd9sNktaWpqEhISIiEhISIjk5+dLenq6arN161aprKyU4OBg1WbHjh1SVlam2mzZskX8/f1rPYRJRESPsbseuniXBg0ahKZNm6pLD7777ju4ublhwoQJqk1SUhJcXFywdu1aHDx4EH369Kn10oMnn3wSaWlp2LVrF5544gnNpQf5+fnw8PDAgAEDcPjwYaxYsQKOjo689IDFYrEes3oglx6YzWa89dZb8PHxgb29PVq2bIlJkyZpLhGorKzElClT4OHhAaPRiO7du+PEiROa5Vy9ehVRUVGoX78+nJycEBMTg4KCAk2bzMxMhIaGwmg0omnTpkhKSrqnvjLsWCwW69Gvuwk7A1Dt1iaPGbPZLM7Ozg+6G0RE9DuYTCZxcnK6bRveG5OIiHSPYUdERLrHsCMiIt1j2BERke4x7IiISPcYdkREpHsMOyIi0j2GHRER6R7DjoiIdI9hR0REusewIyIi3WPYERGR7jHsiIhI9xh2RESkeww7IiLSPYYdERHpHsOOiIh0j2FHRES6x7AjIiLdY9gREZHuMeyIiEj3GHZERKR7DDsiItI9hh0REekew46IiHSPYUdERLrHsCMiIt1j2BERke4x7IiISPcYdkREpHsMOyIi0r17DrsdO3bIiy++KF5eXmIwGGTNmjWa+QBk6tSp0qRJE3FwcJCwsDA5efKkpk1eXp5ER0eLk5OTuLi4yODBg+X69euaNgcPHpRnn31W7O3txdvbW2bNmlWjL6tWrZKAgACxt7eX9u3by4YNG+51dYiI6HGAe7RhwwZMmjQJ3333HUQEq1ev1sxPSkqCs7Mz1qxZg8zMTPTu3RstWrRAUVGRatOrVy907NgRe/bswc6dO+Hn54eoqCg132QywcPDA9HR0Th8+DCWL18OBwcHLFy4ULX5+eefYW1tjVmzZuHo0aOYPHkybG1tcejQobteF5PJBBFhsVgs1iNcJpPpjp/39xx2mgeLNuwqKyvh6emJ2bNnq2n5+fkwGo1Yvnw5AODo0aMQEezdu1e12bhxIwwGAy5evAgA+PTTT+Hq6oqSkhLVJj4+Hv7+/urn/v37IzIyUtOf4OBgDB8+/K77z7BjsVisR7/uJuzq9Jzd2bNnJTs7W8LCwtQ0Z2dnCQ4OltTUVBERSU1NFRcXFwkKClJtwsLCxMrKStLS0lSbrl27ip2dnWoTHh4uJ06ckGvXrqk21Z/H0sbyPLUpKSkRs9msKSIi0r86Dbvs7GwREfHw8NBM9/DwUPOys7PF3d1dM9/GxkYaNmyoaVPbMqo/x63aWObXJjExUZydnVV5e3vf6yoSEdEj6LEajZmQkCAmk0lVVlbWg+4SERH9Aeo07Dw9PUVEJCcnRzM9JydHzfP09JTc3FzN/PLycsnLy9O0qW0Z1Z/jVm0s82tjNBrFyclJU0REpH91GnYtWrQQT09PSUlJUdPMZrOkpaVJSEiIiIiEhIRIfn6+pKenqzZbt26VyspKCQ4OVm127NghZWVlqs2WLVvE399fXF1dVZvqz2NpY3keIiIi5a6HLv5/BQUFyMjIQEZGBkQEc+bMQUZGBs6fPw+g6tIDFxcXrF27FgcPHkSfPn1qvfTgySefRFpaGnbt2oUnnnhCc+lBfn4+PDw8MGDAABw+fBgrVqyAo6NjjUsPbGxs8MEHH+DYsWOYNm0aLz1gsVisx7Duy6UH27Ztq/XJBg0aBKDq8oMpU6bAw8MDRqMR3bt3x4kTJzTLuHr1KqKiolC/fn04OTkhJiYGBQUFmjaZmZkIDQ2F0WhE06ZNkZSUVKMvK1euROvWrWFnZ4e2bdti/fr197QuDDsWi8V69Otuws4AAPKYMpvN4uzs/KC7QUREv4PJZLrjGIzHajQmERE9nhh2RESkeww7IiLSPYYdERHpHsOOiIh0j2FHRES6x7AjIiLdY9gREZHuMeyIiEj3GHZERKR7DDsiItI9hh0REekew46IiHSPYUdERLrHsCMiIt1j2BERke4x7IiISPcYdkREpHsMOyIi0j2GHRER6R7DjoiIdI9hR0REusewIyIi3WPYERGR7jHsiIhI9xh2RESkeww7IiLSPYYdERHpHsOOiIh0j2FHRES6x7AjIiLdY9gREZHu3XPY7dixQ1588UXx8vISg8Ega9asUfPKysokPj5e2rdvL/Xq1RMvLy8ZOHCg/Pbbb5pl5OXlSXR0tDg5OYmLi4sMHjxYrl+/rmlz8OBBefbZZ8Xe3l68vb1l1qxZNfqyatUqCQgIEHt7e2nfvr1s2LDhXleHiIgeA/ccdjdu3JCOHTvK/Pnza8wrLCyU/fv3y5QpU2T//v3y3XffyYkTJ6R3796adtHR0XLkyBHZsmWLfP/997Jjxw4ZNmyYmm82m6Vnz57SvHlzSU9Pl9mzZ8s777wjixYtUm12794tUVFRMnjwYMnIyJC+fftK37595fDhw/e6SkREpHf4HUQEq1evvm2bX375BSKC8+fPAwCOHj0KEcHevXtVm40bN8JgMODixYsAgE8//RSurq4oKSlRbeLj4+Hv769+7t+/PyIjIzXPFRwcjOHDh9+yL8XFxTCZTKqysrIgIiwWi8V6hMtkMt0xr+77OTuTySQGg0FcXFxERCQ1NVVcXFwkKChItQkLCxMrKytJS0tTbbp27Sp2dnaqTXh4uJw4cUKuXbum2oSFhWmeKzw8XFJTU2/Zl8TERHF2dlbl7e1dV6tJREQPsfsadsXFxRIfHy9RUVHi5OQkIiLZ2dni7u6uaWdjYyMNGzaU7Oxs1cbDw0PTxvLzndpY5tcmISFBTCaTqqysrN+3gkRE9EiwuV8LLisrk/79+wsAWbBgwf16mntiNBrFaDQ+6G4QEdEf7L6EnSXozp8/L1u3blV7dSIinp6ekpubq2lfXl4ueXl54unpqdrk5ORo2lh+vlMby3wiIiKLOj+MaQm6kydPyo8//iiNGjXSzA8JCZH8/HxJT09X07Zu3SqVlZUSHBys2uzYsUPKyspUmy1btoi/v7+4urqqNikpKZplb9myRUJCQup6lYiI6FF3xyEsNykoKEBGRgYyMjIgIpgzZw4yMjJw/vx5lJaWonfv3mjWrBkOHDiAS5cuqao+srJXr1548sknkZaWhl27duGJJ55AVFSUmp+fnw8PDw8MGDAAhw8fxooVK+Do6IiFCxeqNj///DNsbGzwwQcf4NixY5g2bRpsbW1x6NChu14Xk8n0wEcRsVgsFuv31d2MxrznsNu2bVutTzZo0CCcPXv2lp3Ztm2bWsbVq1cRFRWF+vXrw8nJCTExMSgoKNA8T2ZmJkJDQ2E0GtG0aVMkJSXV6MvKlSvRunVr2NnZoW3btli/fv09rQvDjsVisR79upuwMwCAPKbMZrM4Ozs/6G4QEdHvYDKZNGNDasN7YxIRke4x7IiISPcYdkREpHsMOyIi0j2GHRER6R7DjoiIdI9hR0REusewIyIi3WPYERGR7jHsiIhI9xh2RESkeww7IiLSPYYdERHpHsOOiIh0j2FHRES6x7AjIiLdY9gREZHuMeyIiEj3GHZERKR7DDsiItI9hh0REekew46IiHSPYUdERLrHsCMiIt1j2BERke4x7IiISPcYdkREpHsMOyIi0j2GHRER6R7DjoiIdI9hR0REunfPYbdjxw558cUXxcvLSwwGg6xZs+aWbUeMGCEGg0E++ugjzfS8vDyJjo4WJycncXFxkcGDB8v169c1bQ4ePCjPPvus2Nvbi7e3t8yaNavG8letWiUBAQFib28v7du3lw0bNtzr6hAR0WPgnsPuxo0b0rFjR5k/f/5t261evVr27NkjXl5eNeZFR0fLkSNHZMuWLfL999/Ljh07ZNiwYWq+2WyWnj17SvPmzSU9PV1mz54t77zzjixatEi12b17t0RFRcngwYMlIyND+vbtK3379pXDhw/f6yoREZHe4XcQEaxevbrG9P/85z9o2rQpDh8+jObNm2Pu3Llq3tGjRyEi2Lt3r5q2ceNGGAwGXLx4EQDw6aefwtXVFSUlJapNfHw8/P391c/9+/dHZGSk5nmDg4MxfPjwu+6/yWSCiLBYLBbrES6TyXTHz/s6P2dXWVkpAwYMkLi4OGnbtm2N+ampqeLi4iJBQUFqWlhYmFhZWUlaWppq07VrV7Gzs1NtwsPD5cSJE3Lt2jXVJiwsTLPs8PBwSU1NvWXfSkpKxGw2a4qIiPSvzsPu/fffFxsbGxk9enSt87Ozs8Xd3V0zzcbGRho2bCjZ2dmqjYeHh6aN5ec7tbHMr01iYqI4Ozur8vb2vreVIyKiR1Kdhl16erp8/PHHsmTJEjEYDHW56DqRkJAgJpNJVVZW1oPuEhER/QHqNOx27twpubm54uPjIzY2NmJjYyPnz5+XcePGia+vr4iIeHp6Sm5uruZx5eXlkpeXJ56enqpNTk6Opo3l5zu1scyvjdFoFCcnJ00REZH+1WnYDRgwQA4ePCgHDhxQ5eXlJXFxcfLDDz+IiEhISIjk5+dLenq6etzWrVulsrJSgoODVZsdO3ZIWVmZarNlyxbx9/cXV1dX1SYlJUXz/Fu2bJGQkJC6XCUiItKDux66+P8VFBQgIyMDGRkZEBHMmTMHGRkZOH/+fK3tbx6NCQC9evXCk08+ibS0NOzatQtPPPEEoqKi1Pz8/Hx4eHhgwIABOHz4MFasWAFHR0csXLhQtfn5559hY2ODDz74AMeOHcO0adNga2uLQ4cO3fW6cDQmi8ViPfp1N6Mx7znstm3bVuuTDRo0qNb2tYXd1atXERUVhfr168PJyQkxMTEoKCjQtMnMzERoaCiMRiOaNm2KpKSkGsteuXIlWrduDTs7O7Rt2xbr16+/p3Vh2LFYLNajX3cTdgYAkMeU2WwWZ2fnB90NIiL6HUwm0x3HYPDemEREpHsMOyIi0j2GHRER6R7DjoiIdI9hR0REusewIyIi3WPYERGR7jHsiIhI9xh2RESkeww7IiLSPYYdERHpHsOOiIh0j2FHRES6x7AjIiLdY9gREZHuMeyIiEj3GHZERKR7DDsiItI9hh0REekew46IiHSPYUdERLrHsCMiIt1j2BERke4x7IiISPcYdkREpHsMOyIi0j2GHRER6R7DjoiIdI9hR0REusewIyIi3WPYERGR7jHsiIhI9+457Hbs2CEvvviieHl5icFgkDVr1tRoc+zYMendu7c4OztLvXr15M9//rNcuHBBzS8uLpaRI0dKo0aNpH79+vLSSy9JTk6OZhkXLlyQyMhIcXR0FHd3d4mLi5Py8nJNm+3bt0unTp3EaDSKn5+fLFmy5F5Xh4iIHgP3HHY3btyQjh07yvz582udf/r0aQkNDZWAgADZvn27HDx4UKZMmSL29vaqzdixYyU5OVlWrVolP/30k/z222/y17/+Vc2vqKiQyMhIKS0tld27d8vSpUtlyZIlMnXqVNXm7NmzEhkZKd26dZMDBw7ImDFjZMiQIfLDDz/c6yoREZHe4XcQEaxevVoz7dVXX8Xrr79+y8fk5+fD1tYWq1atUtOOHTsGEUFqaioAYMOGDbCyskJ2drZqs2DBAjg5OaGkpAQAMGHCBLRt27bGc4eHh9/yuYuLi2EymVRlZWVBRFgsFov1CJfJZLpjXtXpObvKykpZv369tG7dWsLDw8Xd3V2Cg4M1hzrT09OlrKxMwsLC1LSAgADx8fGR1NRUERFJTU2V9u3bi4eHh2oTHh4uZrNZjhw5otpUX4aljWUZtUlMTBRnZ2dV3t7edbHaRET0kKvTsMvNzZXr169LUlKS9OrVSzZv3iz9+vWTv/71r/LTTz+JiEh2drbY2dmJi4uL5rEeHh6SnZ2t2lQPOst8y7zbtTGbzVJUVFRr/xISEsRkMqnKysr63etMREQPP5u6XFhlZaWIiPTp00fGjh0rIiKBgYGye/du+eyzz+S5556ry6e7Z0ajUYxG4wPtAxER/fHqdM/Ozc1NbGxspE2bNprpf/rTn9RoTE9PTyktLZX8/HxNm5ycHPH09FRtbh6dafn5Tm2cnJzEwcGhztaJiIgefXUadnZ2dvLnP/9ZTpw4oZn+66+/SvPmzUVE5KmnnhJbW1tJSUlR80+cOCEXLlyQkJAQEREJCQmRQ4cOSW5urmqzZcsWcXJyUkEaEhKiWYaljWUZREREyh2HsNykoKAAGRkZyMjIgIhgzpw5yMjIwPnz5wEA3333HWxtbbFo0SKcPHkS8+bNg7W1NXbu3KmWMWLECPj4+GDr1q3Yt28fQkJCEBISouaXl5ejXbt26NmzJw4cOIBNmzahcePGSEhIUG3OnDkDR0dHxMXF4dixY5g/fz6sra2xadOmu14Xk8n0wEcRsVgsFuv31d2MxrznsNu2bVutTzZo0CDV5osvvoCfnx/s7e3RsWNHrFmzRrOMoqIi/P3vf4erqyscHR3Rr18/XLp0SdPm3LlziIiIgIODA9zc3DBu3DiUlZXV6EtgYCDs7OzQsmVLLF68+J7WhWHHYrFYj37dTdgZAEAeU2azWZydnR90N4iI6HcwmUzi5OR02za8NyYREekew46IiHSvTq+zo7rVvXt3sba2ls2bN9/T455++mnZv3+/5sbZjo6O8uSTT0q9evXk2LFjt7ygvkePHrJly5Ya0319feXcuXMiImIwGOT5558XW1tb2bx5szg7O0twcPAd+9mzZ08RkTu269q1q1hbW0tmZqbk5eXdtu0fpUePHrJ79265ceOGZnrPnj0FgJSWlkpqaqqUlpaq6SIihYWFsmvXLgkNDZXi4mLZt2/fHZ+rZ8+esm3bNunWrZtcuHBBjh8/fsfHWFtbS9euXcXW1lZNu3LlimRmZkr37t2loqJC/WwREBAgDRs2lN27d0uDBg2kc+fOIlJ1/1srKyspLS2Vw4cPyzPPPCO7du0SZ2fnGpf7VP/9GAwGqaioUP9u27ZNunbtKuXl5XL16lVp3ry5mM1msbKykuzsbLGyspKcnBwpLS2Vzp07S0ZGhpjNZrVMo9Gors29fv267N69W80LCgrS/C4dHR0lNDRUKioqxNraWiorK+XHH3+s0T/Le69x48Zy+fJlzXOVlJSIp6enGI1GOX/+/B1/55bXWOTO72l68Lhn9xD7/vvvJTk5+Z4fZzabZc6cOfLUU0+paT/++KN88cUXsm7duts+NjAwsNbpL730kowfP179vGrVKlm7dq107txZrK2tJTk5WWbPnn3bZSclJUmXLl3UzwkJCdKoUaMa7ezs7KRBgwbi7u5+2+X9kYKCgjRBYhEdHS2tW7eWiooKzcbF0KFDpV+/fmJtbS0iImVlZTWuLb2VDz/8UCZMmCAzZsyQpKSkW7azsqr68+3Ro4csWbJE6tWrJ2vXrpXk5GRZvXq1tG/fXioqKiQpKUlCQ0NrBHXHjh2lsLBQ3N3dJSYmRpo1ayZt2rSRwsJCKS8vF7PZLG3atJHVq1dLRESE7NixQz22+rWsjo6O4uPjIxERETJ69GhZsGCBLF26VEREWrZsKQ4ODvLvf/9bVq5cKdevX5cnnnhCnnzySVm2bJls2LBBNmzYIAaDQUaPHi0Gg0F8fX1F5H/f/8nJybJlyxYJCAgQkaqNrW3btmnW5f3335dvv/1WmjRpImPGjJEmTZpo5vv6+sratWtlzpw5EhYWpu7oZLFx40YREVm5cqW8/PLLYmdnJ40bN1a/49qsW7dO/v3vf/9Xf6P0ANzT8EWdeRhHYzZq1Ej9PzY2FrNmzfqvlpObm4uffvpJ/fzxxx8jNjYW77zzzn+1vMuXL6OiogL169eHiKBz586IiYnB1KlT1fNdunQJjRs3rvXxBoMBXl5eNfq4d+/eWtv7+/vjyJEjd92/5s2bo3PnzvftdVm+fDlmzJihfrb8HqysrGptb2Njg927d6vH+Pr6IjAwUNPG1tYWdnZ2sLW1RYcOHdT07Oxs5OXl4YUXXsDOnTvV9LFjx2qeb/78+YiNjUVAQACKioogIigoKEBRURFeeukl1KtXDy4uLnB1dYXBYFCPe/HFF9X/69Wrh5MnT95yPQwGAyIjI2Fra4uXX34ZIoJevXph/Pjxqs3777+Pzp07o379+jAajejQoQM++ugjzXJatmyJ0NBQ9OjRA9euXUNUVBRGjRqF2NhYFBUVwc3NDcnJyWjTpg0aN26Mnj17IiEhAcuXL8eFCxdQVlYGW1tbiAi+/PJLFBQUwNfXV007f/48xo0bh4iICBiNRnTr1g0iAhcXF9SrVw8GgwG5ublYtWoVDh06hLKyMs37cdq0afD29kbz5s1hMBiwfv16rFmzBomJiejdu3etv5tvvvkGy5YtQ2Zm5n1737Huru7LpQd68jCG3f79+//rxzo6OkKk6oP1hRde0ATP3LlzsXv3bqSmpv5Xy+7RowdKS0s1H5TVy8/PDy1btkRUVJSaZmNjg1atWkFEsHDhQqxZswYiAmtra4gIli5diqeffrrW5TVr1uyewuvixYswm83qw6+ua+XKlSrgRAS7d+/GgAEDbtm+VatWmDdvHhISEiBStXEwZswYvPTSS6rNt99+i+TkZCQnJyM/Px9RUVGYO3cuYmJiEBkZCYPBgAkTJqj2J0+eVP+3trZGly5d8NZbb+GHH35QYffFF1/g+eefh4ggPj4eCxcuhIjAaDSqwKu+ETF79mzNcu9UdnZ22Lt3L2xsbNS0GzduIC8vT9Ou+noaDAb13G+88QYmTJiAt956S/1eEhIS4O7ujqCgIPWYlJQUbNq0CVZWVmjWrJl6X7m4uKhAP3fuHNauXQsRwYoVK7Bx40YkJydDRHDt2jUMGzYMBw8eRFpaGubNmwd/f39YW1tj/fr1iIqKwpYtWzR9PnfuHLp06YLAwED07t0bEyZMQGhoqGajsXpZW1vDysoKzs7O9+U9x7r7YtjdwcMYdqGhoZqfXVxc8M477yAqKgrdu3eHr6+v2iqeNm0aRKou7BcRFSaZmZnqD7ldu3YQEcTExKBz584ICAi4q360bNmyxrSxY8di6dKlEPnfwLL0sbZlrF27FocOHYKIYPjw4ejevTsGDhyIVatWQaTqA7i2x7m6utb6/Ler7777DgUFBfjmm29uudzfU9XXV0Rw9uxZfPvtt7dsn5OTU+v0goIC9f+4uDgAQFZWFrKysuDu7q4+rC1VfY/Lz88P8+bNw5tvvolVq1YhMjISKSkpmDlzJiZPngyRqmCxt7eHt7c3xo8fj3r16kGkKjx69OgBkaprYi3LdHZ2xjPPPHPXv4e33noLbm5uaNKkierfzJkz1Z6UpebPn682PF599VV8/vnnaN26NWJjYzXtTCYTfvnlF/Tv318z3cHBAa+88grs7e0hIli/fr16rz/11FPo3bs3hgwZokIwLy8PycnJqn1oaChOnz6Nq1evAgDGjh0LEUG/fv1w9OhRiIjaGHz33XfV+3XevHm4cuUKpk2bhszMTPTu3RvTp09X/bIs/+bXhvVgi2F3Bw9j2N1c+/fvR3l5Ob799lvk5ORg3LhxMJvNOHTokNqaP3fuHKysrNC3b1+ICAoLC/Hjjz9CRPDmm29i4sSJuHHjBvz8/G75PE5OTpqfL126VKNNs2bNEBoaCoPBgK+++grNmzeHiODgwYO1LnPEiBHo1auX+vnUqVOoqKhAZmam2uMT0X6AiFTteWRnZ9/T7+mrr75Cbm4uTCaTWvf7UZYPzaZNm6q9m9qC2bLhISLw8PBAmzZtYG1tjZKSEjRs2FDtZbz55puYNWuW+gCuV6+e2kMXqdpjad26NXx9fbF//371oT5mzBgVbEuWLKnx3YwBAQHo06eP+vm9995TgfTvf/9b03b27Nlo0qSJ2vvy9/dH06ZN0bRpU027999/H7a2tvjss89w+vRpiFQd3r127Rrq1auH4cOHQ0QQERGBkSNHYvXq1fDz84OPjw/69esHDw8PJCUlaZbZr18/uLu7o6ysDCICNzc3WFtbw9bWFvn5+WrDqFu3bnBwcICrqytEBEOHDkVAQIA6MvDtt99qjiqICJo0aQKz2Yxt27bhhRdeQM+ePdGnTx+cOXNG066yshJDhgyBo6MjrKyssHDhQsTFxeGTTz5RbRo1aoQPP/xQbYy0adMGX3311X3/+2fdXTHs7uBhDDt/f3+0bdsWBoMBjo6O+PTTT1FZWYnk5GRcuHABrVq1wuXLlzF79mwUFhZCpOow0tKlS9WhpKioKBV8IlVb4zExMZrzgdW3So1GI9LT0zX9+Oc//6n+7+vrCxFBYmIiPv/8c7Rs2RIZGRnq/B+AWtelYcOGyMnJUXt+I0eOxKJFi+Dt7Y0DBw5ApOq81fbt2+Hr64vXX38dIoLffvsNX3zxBUQEgYGBKlRvVwkJCdiwYYN6be/X67Np0yb1f0soZWdnaw6fTpw4UROAp06dwpUrVzBnzhzMmTMHQUFBmjD38vLCzJkzISL44YcfNOfpTp48iS+//BLTp09HTEwMxo0bpzmcKiIoLS1FTExMjb6Wlpaq/3fu3Bnz5s1D/fr18d1332naWVlZ4ezZs/D19YWPjw+uXLmClJQU9Z546623MG7cOPz8889qWZZll5WVwWQyYceOHSocFixYgPnz5yMqKgq5ubkQqdr7b9asGUSqNhTCwsLUEQmDwYAxY8ZARLBnzx7MnTsXycnJiIuLU+c5v/vuO/z0009qr/3MmTOwt7dXoRsTE4MvvvhCBe6QIUPQpk0bLFu2DIGBgSgpKVEbBJ6enpr1Hzp0qOZ86unTp7F582bN+8jLywsVFRVqD3rEiBEYNmzYbd8rDRo0QL169WBtbY0GDRrUmNegQQP1d96gQQPY2Nio6dXnW14jyzIaNGgABwcH1cby//r162seZ/l/9ed1cHDQHKWwnM+8ue+2trawt7fX9Ovm/t/8GMtGq2UjsHofRUT9Hqo/tvpzV19vSx8t82tbl+rFsLuDhzHsrly5gqtXryI6Ohrz5s2Do6MjysvL8dVXX+H48eNwc3ODyWTC/v371aEyy7oA2g/51157DSJVg1NsbW3x9ddfw87ODiKCDz74QLV78803NYfXLG9My/8te3nW1tZYvHgxLl26hLi4OPVG/PLLL9Ub0hKMliosLFT3Ua3+5q2oqICI4Omnn0ZpaSl27NiBxYsXQ6QqXA0GA4KCgtRhrrv53bVr1w4AcOXKlfvy2lhZWSEiIgKxsbGYMGGCOlRcWVmp9kBEqg5VRkdHq59TU1MRExOjCSTLYA/LB4vl/1999ZUKPhGBu7s7bG1t1e+tpKQEmzdv1pzfqqysxK+//qp+njZtGl588UUsWrRITQsMDERWVhZSUlKQmJionjMqKgodO3bE1atXkZycjLNnzwIA3N3d1SHwwsJCzJ49G3FxcRARLFmyBMXFxTAYDOjXrx+6deuGM2fOoHXr1uo1rl+/Pl5//XVUVlZCRLBt2zacP38eIoJly5YhKysL4eHhGDt2rAooSz9ffvllFBYWas4D+vn5YfTo0WrgS9OmTfHKK6+ovdeioiKUl5dj3LhxEBEEBQWhXbt2OHfuHNatW4fKykpcvXpV83r6+vqia9euqs8NGzaESNURjAYNGqCiokLzex44cCAcHR3RqVOn275P/P39ISJYtGgR/vGPf8DFxUUdERCpOny6f/9+7N+/H23btkViYiJSU1Ph6uqKLVu2YP/+/er9NXr0aIhUnd/et28fmjVrhq+++gojR45Ev3798PPPP8PHxwfp6en48ccfsW3bNixduhR9+/bFmjVrMH78eAwcOBCxsbGYN28ehg8fjm+++Ubz3qx+Xnjs2LH4+OOPkZycjA8//BCbNm3CmjVrNBtgIoL09HR1KNtybv3LL7+Eg4MD1q1bh+7duyM5ORn79+9X561XrFiBPXv2YMeOHfD19YW1tTW+/PJLdcQhPT0daWlp2Lp1K5o3b46IiAjMmzcPIoLIyEj1/9qKYXcHD2PYzZgxA+PGjUPz5s3VOY7Lly9j//79WLVqFSIiIlBRUYEePXrgt99+g8j/jt4DqsIuLCwMERER6nBVXFwc3n33XcTExKgPzeofqPb29ujRowemTp2K999/X/NhYNkLiYiIgIhg37592LFjhzpfaPmgEBGkpaXhueee06xPaGioJggsNXToUBUgkZGRcHd3R2hoqOawp52dHbKysrB69eq7+t1t374dlZWVNQ7p1VX985//xLlz51BeXo7Y2Fh06dIFIlV7EV26dFF7HUFBQdi9e7d6XPXDkrXV4MGD1VZrbeeBrKysEBgYCIPBgFWrVuGdd97RnNudOnWq5pzZmDFjUFpaqkZ7ilQdhjt+/Di+++47vPnmm2pgR1RUFNq1a4e4uDiEhobihRdeUO8jS+3cuRMGg0EF5KJFizB58mS0bdsWUVFRaNmyJYKCgpCWlgYRgY+PD3bv3o3OnTure+kOHz4ce/bsQb169TBu3Di88MILWLBgAQBoBngYDAY4OTkhMjISpaWliI6Ohr29vToE37ZtWzRt2hSTJk3C8ePH4eHhASsrKxQXF2P06NEYOnQoIiMj0a1bN/z6669o2rQpMjMzMWTIkBrnq1NSUtSArerrZ6nS0lJ88803GDhwIBITEyEi2LBhQ62Hyav//i0bW9euXVODf6qfi922bRsuXbqEo0ePwt3dHa+88goOHjyId955B6tWrUJ6ejq+++47BAQEwM/PD/Xr18c777yDyspKnDlzBrNmzVIbo3PnzoVI1QbOa6+9hk6dOsHV1RUzZ87Eu+++CxsbGxw/fhxZWVkoLy/HkSNH1N94VFQU8vLyMGnSJIwZMwbDhw/Hhx9+iHXr1iEvLw+ffPIJrly5gpKSElRWVmL8+PEYOXKker5z587h9ddfx8cffwwRQUZGBnbu3IlNmzZh1apVSEhIwI0bN3Dp0iW1kf7mm2+iuLgYx44dQ1xcHBYsWKAeX1xcjN69e6NDhw4wGAz46KOP1NEEEcHevXtrHKq2FMPuDh7GsLOU5c28bNky1dfz589j7969KC0txalTp9SW6unTp3Hx4kUAVR9Sv/32G5YtW6aWUVpaquaJVB1eXLZsGcLDwxEeHq6e58MPP9QE06VLl3D16lVkZWWpP/DIyEh4eHhgxYoVqp3lA3X//v2aUXg3r8ud6siRI2jbtq1mmr+/v2bk3+2qYcOGOHjwoGZd67Ly8vJQXl6OCxcuqGlDhgxR5262bt2q9lKqbwzcqiyjFG1tbeHs7Izg4GCIVIWX5f8igs8//xwJCQlwdnZG//79MXz4cAwZMuS2yx41ahQaNWqk2cO8ceMGrK2tUVBQoM6RTZ48GV5eXjhz5gxeeOEFvPLKKzV+f/Xr18fChQuRnJyMzp07q3OFBoNBHXY9ceIESktL0bNnT8yYMQNfffUVxo8fD3t7ewQHB2P+/Pl45pln4Ovri/79+yMmJgZms1l9WNdWL774IoqLi7F582b89ttviI2NxZkzZxAVFYWPPvoIx44dw969e/HRRx9h8ODBMBgMWL58OVatWoWzZ8+iY8eOEBHN3tnN75fq56oteyqWmj17NhwcHJCTk6MOl0ZHR6tBP9WruLgYDg4O8PPzQ0VFBVxdXdG/f3+1F1h9r8TX1xe+vr5Yt26d2rg5duwYAKhDkaWlpapvlj2vyZMnIyYmRm14itS+cdSuXTu8/PLLeOGFF9C7d280btwYPj4+qKysRElJiWo3Z84cAICfnx8AqL3wbt26YebMmRg5ciQ2bdqE8vJyFBUVISkpSR1uFqkaCLdjxw61sXv16lUkJCTAaDTC19cX27dvR2FhIXJzc+Ho6KjO7c+cORPt2rVDTEwMPvjgA7WRMWDAgBqfFZY924EDB2LevHl47bXXahzGF2HY3dHDGnavvPKK2r3fvHkzKisr8fPPPyMrKwvz5s1DaWkpSkpKcO3aNYiIun4IqPqQKigoQIMGDfDCCy9ApGoQQVlZmTrcsGfPHmRmZuLy5cvqzf/GG29ARBtMs2fPxujRoxEdHa1GYZpMJowdO1Zz7sry/7S0NLVndrth+bXVc889hxs3bvzu3938+fOxdevW+/K6LFmyBL/99psmQPbs2aMuFxk8eHCth7gMBgNsbGzg6OgIg8GAAQMG4L333sOiRYvw+eefqw8sy6Hk9PR0zUaH5VICy2vi5+d3V5dl/OMf/0B2djYCAgLQsWNHpKSkQKTqEPLLL78Mg8GAoqIivPrqq5g3bx4WL16MQ4cOqQ89S3Xp0gWrVq3C5cuXsWTJEohUDboRqTokN2bMGBQWFqKoqAhNmjRBu3btkJaWpj4EExMTER0djcWLF+PkyZPIysqC2WxW79c+ffqoD7zq7z8HBwcAQLdu3TB+/HgsXboUM2fORGpqKrZv345PP/0UGzZswMGDB7Fz5040aNAATk5OmDRpUo1BQ+7u7rX+jqrvzd18mMzDwwPvv/8+1q1bp0ay3uraz7i4OERFReG1115DVFQUXF1dMW3aNCQnJ6NVq1Ywm801HgNAHfodPXq0Gjjj5+eHI0eOwNnZGa1bt0a/fv3u6X166tQpnDlzBtnZ2Wrgk0jVdYHV95REqjZyk5KSsHDhQnWZiuWw45dffomGDRtiwIABiI2NRVRUFJycnGBnZ4f33nsPX3/9tTqPGhAQoNlz3rdvH/7xj38gKytLfc76+flpjnJERERg1qxZ6nD7gAEDsGLFCvj4+Kjf/0svvYQOHTqguLhY7R3ffEhVhGF3Rw9r2O3duxenT59Gt27dUFhYiOLiYuzduxcHDhzAvn37UFxcjIqKCnW4pKSkBEuWLAFQ9eHxz3/+E40aNVKHkCxD2y0n5gMDAxEcHIzAwEDMnTsXc+fOrfV4+O7du3H+/HmYTCakpKTA2toaL7/8shqZJiLo3r272ksAoLbELIc77raysrKwZs0a9Ub/b8vBweG+XHpgZWWFa9euAQCWLVumpru5ucHJyanG7y8qKgp9+vTBlClTsHjxYiQnJ2P37t2YOXMmOnfujKKiIly7dg1nz55F9+7dNX/ETk5OcHBw0Dx39WVX/yC3srKCq6trjYv5mzRpgri4OBw6dAgXL17E+fPn8d5772HgwIEYPHgwxo8fDxsbGzz33HOYNGkSlixZgp9++gmZmZk1RkxmZWWhc+fO8Pf3V2Fn2bO3t7dHQEAAPvroI2zfvh0iVeeKMzMzMWrUKIwdOxZJSUl477338P777yMvLw+BgYEIDw/H9OnTMWzYMJSVlcHe3h7z58/HyJEj1ev39ddf49y5cxCpun5w/fr1cHZ2xpUrVzBx4kSsW7cO8+fPR3x8PAoLC5GQkIAPP/xQDTax/A7r16+vLl24uTZs2KD+bwk+JycnPPfcc+jRo4c6h2k5f1h9FPHNZTAYNCOTc3JyUFhYiPfffx8rV66s0X7jxo2aw5+Wv8/jx4+r4EtOTtaM7L2batOmDWbOnImvvvpKjajt16+fumB//vz56mjJ3r17MWDAAHz99dfYsmWL2iizbJht3boVSUlJuHz5MuLj47F48WJs3LgR33zzDSoqKmAymbB27Vp1HtCyEeTn5wcrKyssXrwYzz//PMaMGYNZs2ahTZs2qp+Ww9eWG0t89NFHiImJUQNjxowZgxEjRmD06NH45JNPEBQUhA4dOqgNj+rFsLuDhzXsnJycMGDAANSrVw8FBQXqu/5+++03PP/888jJyUFZWRny8/MhIigvL0dhYaEa9FF9NJTlD9Tb2/uWf6BDhw5V59CqV3FxMU6fPo2SkpIaAWL5I3333Xdx48YN9OrVC2VlZepyiOpl+QO4XXXo0AENGzaEjY1NjWu27qWsrKwQHByshqjXVt27d9ccCrpTvfjii1i6dClyc3Px7bffYvDgwTXa3Ly1mZWVhZkzZ2Ljxo1Yt24dli5dijlz5mD69Olo1KgRunXrhnbt2qFJkybqd1s94KqXZQCQparfdWb58uU4cuSI+pANDAxEVFSUGl1ZUVGBiooKXL16FTt27MDZs2ch8r/XZo4fPx7Dhg1DfHw8Vq5cic8++0z9jrp3744uXbpg48aN6iJwy5Y5ANSrVw8pKSlYtWoVAgMDcfz4cYhU7UW1adMG0dHRiI6ORmRkJBISEhAZGYnp06drLoHJyclBZWUlWrZsCQDo0qWLOkzVunVrNYKzSZMm6ujChAkTsG7dOly9ehU3btxASUmJuqSl+u9w/vz5mDdvHvbs2XPLjSgANa4TXbFiBcxmM6ytreHj44OKigp1HthgMKBt27aIj4+v9fB69QvQ/fz8kJubi6tXr6rn+OijjzB79mx4eHjc8gYIHTt2VHfUqVev3j3fKKF79+4wm82orKxUfSwqKkJWVhbmzp2LgoICrF69Gh06dMBPP/2EiIgI/PLLLwCAtWvXYufOndi5cyfq16+PvLw87Nu3D1evXkVwcDBat26Nb7/9FtbW1nj//fcxc+ZMPP300+pIxIEDB9Qh9qCgIHz55ZeYPXs2ysrKYGdnh9DQULi4uGjO7VsO11ZUVGD27NlYvHgxpkyZAoPBgJdffhlRUVEoKipCu3btcOXKFbzyyis1zt0x7O7gYQ276vXLL7/gzJkz6g9u69atqKioQHFxMYqKivD8888jPz8fly9frjGi8m7LYDCo827Va//+/eoNbWVlpQLTcujFUpZBNVOmTMGcOXPg4uKCKVOmwGg0okmTJrc9L1NbrV+/vtb+1FZGo1FznZ7lw82yB1Jbvf/++zXW4XZ17NgxTJs2DR06dNAcZpsyZYr6/81BFRsbi2HDhiEhIQEzZsxAx44dMXz4cGRmZqot+MmTJyM2NvaOfak+clNENMPkZ8yYgZSUFCxYsABhYWEYN24cxowZg+LiYpw4cQInT55Ue0IODg747LPPMGXKFLRu3RovvfQSCgoKMGXKFPTo0QPvvPOOWqeSkhLk5+dj7NixmDlzJqytrREbG6vm//DDD2jUqBEGDhyI3r174+jRozh16hSmTJmCU6dOoXXr1pph5adOnYK3tzfi4uJw7NgxiFSFwfjx4zF9+nQEBgZi9+7dmDRpEiZNmoT4+HgkJCRg8uTJsLOzQ3R0NGJjY9UF8FOnTgUAnDlzRv09Ozs7Y/LkyejUqRNGjRqFUaNGobi4GIMHD641mAwGAwBoLhoXEXh7e+Pll19GmzZt0LlzZ6xZs0aFbqtWrdS1rzNnzsSoUaM074ObrxkNDg5GaWmpOgSXkJCAkpISHD16FFFRUTUupq+LsoS/ZePMysoKAPDqq6+iY8eOSExMxMGDB3H16lX4+vqipKQE58+fV7/HiooKlJaWIjU1FceOHcMXX3yBwYMHo3fv3ggNDVWHO4OCgtSIXMtnaadOnVSQWUKzoKBAjaL9+OOPkZmZifz8fPWaTJkyBf7+/li3bh0uXLigQrp3794oLS3F9OnTUVlZiUuXLsFsNuPChQs1LkNg2N3BoxB2sbGxiI+PR0xMDAICAjBlyhT1AdO/f3+4u7ujV69eiI6OrnH46W5r0aJF2Lx5MwwGg+bD/J///Cd27tyJX3/9FaNHj8b58+fh6emJX3/9FfXq1dNsoVv+n5eXh27dumHGjBlISEjA6dOn73qAiWWLfsaMGfj666/v6jE//vgjwsPD1ZZzly5d0KpVqxoXyd9t1XbrJ3d3d8TGxqrDwpY6ffq05nyatbU1nn/+edja2qKkpEQNDDKZTDhw4ACOHDmCQ4cOoW/fvujXrx8AYNasWeow5s3VunVr9OrVC0899ZRm+s2Xd9SvXx+tW7fWHGLr06cPAKC8vBwAUFZWBldXV/zyyy9Yu3YtZs6ciXfeeQdPP/00xo0bB19fX+Tn56vzdYWFhSgoKEBWVhZOnDgBkarBQpYP7ep7+suXL0dlZSW2bdumRliOHDkSY8eOVYdXn3vuOVhZWeH5559X53Y6deqkuezA0dER58+fx9WrV/Hyyy9j37596rKTsrIyPPPMMzh06BBcXV0RGRmJxMRE9O/fHxcuXFDnpubOnQuz2YyysjLs2bMH4eHhmnO41e9z6e/vj7Fjx9bYmIiLi8POnTsRGhqKlJQU+Pr6ao4EeHl5IT8/H6dPn8a7776L9PR09Xdj2ZCx/Ozt7Y3Y2Fj1GtrZ2eHDDz/Ee++9h0mTJqm7t9RlHT16FFeuXEG7du3w73//G02bNsVXX32F+Ph4REREIC4uDq+99praMJ07dy7+8Y9/4IcffsDUqVMxcOBAzJgxA4sXL0ZgYCAmT56sLrM5c+aMOm0xbtw4LFiwAKdPn1bvi/j4eLi5uWHGjBmIjY3F6tWr0a9fP7Rr1w6NGzfGqFGjUF5eju7du6vD82fPnkVaWhpsbGwwa9YsvPHGGxg1ahSWLFmixiXEx8djyJAh6NSpU63X3TLs7uBRCLvNmzfj4MGDWLduHbZt24ZDhw7h9ddfx88//6yurTpy5AjS0tJQXFysOVxZ/cbFt6sZM2ZgyJAh+PLLLzXX4GRkZGDJkiVISEhA06ZNUV5eDoPBgPDwcOzevVtdMCxSteUuUnXNjeVNbDQasXnz5js+f6dOnTB06FAsX74cc+bMgbW19S0PM7700kuakYgmkwl79uy55V1c7racnJxgNBpx4MABvPXWW/D19dXsXTo4ONQYnODh4aG5ds7Ozg7Z2dmYNm0ahg4diqioKABAYGAgvLy84OHhoUK5rKwMV69e1dxQ2VKWD8rvvvsOa9asqfV1rD4icOnSpdi9e7fak7JcQzlhwgSYzWZMnDgRAHDo0CEMHDgQNjY2MBgMNe6oY7mWKSAgANHR0YiKisL48ePRuHFj2NvbIyEhQR1SmzhxIpydndG5c2cMHDgQs2bNQoMGDdC8eXNkZ2ejoKAAkydPxq+//gqj0Yi1a9fi448/VgNrLGFpOTQpUnVeKSgoCElJSfj0009x9uxZLFy4EFOmTMHZs2cRGBiIFStW1HhvfP755+oaOZGqw5Dl5eVqYEf1Ix5JSUmwt7dXh2WHDBmizqdZWVnB1tYW48aNw4QJE9CuXTt10fWNGzfUofFWrVph5MiRaNmyJebMmYOffvoJK1asQP/+/dWlBsuWLUO3bt1w+vRpxMfHq+e/+YL++1GWm4O3a9cOCxcuxOLFi1GvXj18/vnnWLdunWq3YcMGrFu3Dnv37lUbtv3790fPnj2Rn5+P8vJy+Pn5YcSIEWojKCkpSQVQx44dUVZWhqZNm6q7z/Tp0webN2/G0KFDERoaik8//RSbN2/G7t271UCum+/FmpeXpz4/9u7diwkTJmDKlCkYO3YsAgMDMWvWrFovfK9eDLs7eBTC7qOPPkJpaanaS6isrMS1a9fU3eJFqg5bWO7wUP1YtmXkVW17ByKCrl27qsMzlj/86od0oqKiNB/mlvNSbm5uiIuLQ0JCgjqkVtvyRf73sgQ/Pz9ERkbW2iY0NBTp6ekoKSnBxYsXa8wPCgpCaGgoXn/9dVy8eFFzHV1gYCAAaD40Rar2EmobonyrysjIQHJyMiZOnIhvv/0WFy9erHE7qOofqLeqjh07au5Uc/Xq1Rr3OxWpOlfWo0cPzSUGlrKMTvP29sbq1auRnJyMZ555RnOe47333tM8Z0pKivpdV79W0nJe9+zZs1izZg0WLFiA5s2bo0+fPhg8eDAmTpyoBjFYWVmha9eu2Lx5M86fP4/k5GR1p5tFixYB+N9LEgCgefPmKCgoQMOGDdWWfdu2bREQEIAXX3wR9evXVxsILi4uiIiIQJMmTfD000/j008/Ve8xa2trBAUF4b333sPChQvh4uKC0tJSrFq1Cj4+PgCqBog888wzNYamR0REoKioSHPezcrKChkZGbC2tkazZs3UheOtWrVS15pa3vf16tWDg4MDxo4di9GjR2P06NGYNGmS5lZpixYtwuXLl/HDDz9ApOq61mvXrmH69OnIz8/H559/rg63Wf7mwsLCEBMTg1GjRmk+Z6r/Du9XpaWlwdfXF15eXigtLUVZWRl27twJAGoksaOjIyIiIuDl5YW+ffuiWbNmeOqpp3Djxg01AM6yBydS9a0SlusZLYeST58+DbPZjAkTJuCLL77A8uXLISIYNmyYet9MnDgRbm5umD17NsaNG4fhw4er28dZNh6AqpsYTJkyBePGjauxQQBAc+u2mz9bRBh2d/Swhl3r1q3h5eWFtm3bokGDBrhx4wZWr14NACgpKQEA+Pj4oLy8HCL/u+UKaP+QLIMJ9uzZUyMMRKpO4N/uPpJRUVGIjIzEyJEj4ezsrNnrE6m6RCIvLw9t27atcQumm2vYsGG3vN5JpOrOIa+99lqNQ3QiVYMpLHsQ/v7+NdpY7uZRfZq1tfU9fcNDZWUlKioqYGdnh+DgYAC452+IqO16woCAADz//PNo1KhRrYOALI+rfnskyyCHpUuX4vLly1ixYgXGjh2refzEiRM1yzh27Jg6BOvg4ABfX19069YNEydOxJAhQ7Bp0yZs27YNx48fx2+//YbJkyfjiy++QEFBgWaPNTQ0FMeOHUNBQQF8fHzUa9axY0e1hxIWFobCwkJYWVnh9OnTOHDgAHJzc9GwYcMaQ/4th2KrTzObzfD398ecOXPUfVb79OmDhQsXws3NDV27dlUX7587dw7FxcWaIfTV65NPPsHu3bvVEYSXXnoJBoNBfTXWjBkzMGzYMNjZ2eH48eMwGo3qd1194IflK4psbW1hZWWluWvPq6++qr4WyNraGitWrEBxcTH+/e9/o6CgQI3CHDhwYK23bbNc7ydStfFhuTPN/arffvtNbTReu3YN5eXlMJlMuHbtGsaOHYspU6ao4BYRdXi5ZcuWOHToEC5duoQPPvhAhV2zZs0QEBCAzp07o7CwUAW6v78/CgsLsXPnTly6dEltDBcVFalbGYpUnads164d5s6di6FDh8LDwwMFBQVIS0vD+PHjkZqaqq6R9PT0rHFP1oSEBE3wilQdFu/QoYP6m2DY3cHDGnbZ2dmYMGECjhw5gs2bN+PKlSs4evQoAKh79sXGxqK0tBQGg0FdKwfUvtXo5OSEDh061Aibjz76CK+88sod+2P5rrCffvoJNjY26vDQ6dOn1Ulvy1fS1PZ4y4Wj1S9Ivbnq1auHp556CitXroTBYEBoaKg6H3anQxi3Gr158/Vit6sffvgBFRUVcHNzw9q1a7Fu3boadz65XT969OhR4zyj5fZpgYGBaNiwoepP9Q2D2NhYrFy5Ut1F4p133sGZM2fwySefYOjQoTCbzbWO/ly4cKE6XNy5c2fNiNexY8fis88+w7Jly1BQUKAuCs7KylIDBqKiomBlZYWsrCzVb8seaYcOHdQ1j/Hx8XjzzTc1z71kyRKUlpbC2toaFy9exL59+1BaWoqmTZvi9ddfV4M0OnTogCVLlmDZsmXqdxcQEKAOy+bk5CA8PBzJyckICgrCwIED1d64l5cXhg4diq+++gpvvvmmurSjekAZDAZ1z8hWrVph0KBBWLFiBQwGA1588UV4e3vDYDDg0KFDWLVqFbZt24atW7diypQpGD9+/C1v5NypUydMmzZNXXt64MAB5OTkAAC8vLwQExODoqIiNGrUSN0CzcXFBRcuXFB7NJa6eSRlUlISLl26VOvh67qqixcvqu/Y27FjB+bPn49169YhKChInYu17PGLVG1UzZ8/H0ePHoWrqyt8fX2RkpKiLiWZPn066tevj7i4OMyePRuJiYlqr2rYsGHo378/pk6dqm4o8c0336hLkESqgui9997DoEGDsG3bNvTr1w8xMTHo27cvEhMT1Wter149TJ06FQsWLEDfvn3VHYpERJ03Fqk6wlJUVASDwaDu2sOwu4PqL/jDVJYv3vTx8cEXX3yBc+fO4fLly7h8+TLeeOMNXL58GW+99RZyc3PRsWNHde7s8uXLahm17UXc6WtzoqOj8be//a3G9CZNmuA///kPjEYjFixYoO6V+fe//1216d+/v+aLZqsvJz09HfPnz8f27dtrveODnZ0d1q5dizNnzuDy5cuYPn06fvzxR3VY5L+t6r+PO5WDg4Nq/7e//Q1NmjTBm2++qdlAqH6e7Obg+89//oO//OUvmmmbN2/G3Llzcfr0acTExKg9NsuWsdFoRG5uLi5fvqyuq5o4cSJmzpyJnJwchIWFqa+auV3fb35d7ezsYG1tDXt7e6xfvx6ZmZkYMWIEmjZtCnt7e+Tm5qobUVe/HdvPP/+s7qFo2ZPKyMjQfOiIVN366/3334eDgwP+8pe/ICMjQ/MtGZYBST4+PnB2dkbDhg3V7zEjI0OFa8uWLWFtbY169erhf/7nf2rsSVtukVZ9WvVLSmbNmqX5uqIvvvhC7bWlpKSoe7K6urri0KFDeP7553HhwgVkZWWpEK4+klKkai+nf//+yM7OVveenTFjBjZt2qTeH5MmTcLbb78Nkaq9vup/Azcf6l6+fLl6fSIiIrB9+3bk5uZqznf/3rr5nK63t7fay7/55swLFy7EZ599pvlbDQ8PR9OmTfHuu+9ixIgR6N27N+bNm6dGXVr2tHbt2oVdu3YhPT1dM6gnIiICly5dUpd3WFlZ4bPPPkPDhg3RqlUrtUEgIjX+RuLj4/E///M/6mej0Yjly5fj9OnTOH/+vPrdVf+97tixA+vXr4eNjY3auMjPz7/j570BAOQxdebMGWnVqtWD7gYREf0OWVlZ0qxZs9u2sfmD+vJQatiwoYiIXLhwQZydnR9wb+qG2WwWb29vycrKEicnpwfdnTrBdXo0cJ0eDXpaJwBSUFAgXl5ed2z7WIedlZWViIg4Ozs/8i/6zZycnLhOjwCu06OB6/TwutsdFav73A8iIqIHjmFHRES691iHndFolGnTponRaHzQXakzXKdHA9fp0cB10o/HejQmERE9Hh7rPTsiIno8MOyIiEj3GHZERKR7DDsiItI9hh0REeneYxt28+fPF19fX7G3t5fg4GD55ZdfHnSXREQkMTFR/vznP0uDBg3E3d1d+vbtKydOnNC0ef7558VgMGhqxIgRmjYXLlyQyMhIcXR0FHd3d4mLi5Py8nJNm+3bt0unTp3EaDSKn5+fLFmy5L6s0zvvvFOjvwEBAWp+cXGxjBw5Uho1aiT169eXl156SXJych7a9bHw9fWtsV4Gg0FGjhwpIo/G67Rjxw558cUXxcvLSwwGg6xZs0YzH4BMnTpVmjRpIg4ODhIWFiYnT57UtMnLy5Po6GhxcnISFxcXGTx4sFy/fl3T5uDBg/Lss8+Kvb29eHt7y6xZs2r0ZdWqVRIQECD29vbSvn172bBhQ52vU1lZmcTHx0v79u2lXr164uXlJQMHDpTffvtNs4zaXtukpKSHcp1ERN54440a/e3Vq5emzcP2Ov3h7uvXCjykVqxYATs7O3z55Zc4cuQIhg4dChcXF/U1Hg9SeHg4Fi9ejMOHD+PAgQP4y1/+Ah8fH1y/fl21ee655zB06FBcunRJVfWvuCgvL0e7du0QFhaGjIwMbNiwAW5ubkhISFBtzpw5A0dHR7z99ts4evQo5s2bB2tra2zatKnO12natGlo27atpr+XL19W80eMGAFvb2+kpKRg37596Ny5M5555pmHdn0scnNzNeu0ZcsWiAi2bdsG4NF4nTZs2IBJkyapL8y0fG+iRVJSEpydnbFmzRpkZmaid+/eaNGiBYqKilSbXr16oWPHjtizZw927twJPz8/9S3tQNVXaXl4eCA6OhqHDx/G8uXL4eDggIULF6o2P//8M6ytrTFr1iwcPXoUkydPhq2tLQ4dOlSn65Sfn4+wsDB88803OH78OFJTU/H000/jqaee0iyjefPmmDFjhua1q/43+DCtEwAMGjQIvXr10vQ3Ly9P0+Zhe53+aI9l2D399NMYOXKk+rmiogJeXl5ITEx8gL2qneWrQH766Sc17bnnnsNbb711y8ds2LABVlZWyM7OVtMWLFgAJycn9eWvEyZMQNu2bTWPe/XVVxEeHl63K4CqsOvYsWOt8/Lz82Fra4tVq1apaceOHYOIIDU1FcDDtz638tZbb6FVq1aorKwE8Oi9Tjd/iFZWVsLT0xOzZ89W0/Lz89XXsABQXwW0d+9e1Wbjxo0wGAy4ePEiAODTTz+Fq6urWicAiI+Ph7+/v/q5f//+iIyM1PQnODgYw4cPr9N1qo3li1rPnz+vpjVv3hxz58695WMetnUaNGgQ+vTpc8vHPOyv0x/hsTuMWVpaKunp6RIWFqamWVlZSVhYmKSmpj7AntXOZDKJyP9+Q4PF119/LW5ubtKuXTtJSEiQwsJCNS81NVXat28vHh4ealp4eLiYzWY5cuSIalP9d2Bpc79+BydPnhQvLy9p2bKlREdHy4ULF0REJD09XcrKyjR9CQgIEB8fH9WXh3F9blZaWir/+te/5G9/+5sYDAY1/VF7nao7e/asZGdna57f2dlZgoODNa+Ni4uLBAUFqTZhYWFiZWUlaWlpqk3Xrl3Fzs5Osw4nTpyQa9euqTYPaj1NJpMYDAZxcXHRTE9KSpJGjRrJk08+KbNnz9YcXn4Y12n79u3i7u4u/v7+EhsbK1evXtX091F/nX6vx+5bD65cuSIVFRWaDxgREQ8PDzl+/PgD6lXtKisrZcyYMdKlSxdp166dmv5//s//kebNm4uXl5ccPHhQ4uPj5cSJE/Ldd9+JiEh2dnat62eZd7s2ZrNZioqKxMHBoc7WIzg4WJYsWSL+/v5y6dIlmT59ujz77LNy+PBhyc7OFjs7uxofNB4eHnfs64Nan9qsWbNG8vPz5Y033lDTHrXX6WaWPtT2/NX75+7urplvY2MjDRs21LRp0aJFjWVY5rm6ut5yPS3LuF+Ki4slPj5eoqKiNN8AMHr0aOnUqZM0bNhQdu/eLQkJCXLp0iWZM2fOQ7lOvXr1kr/+9a/SokULOX36tPzP//yPRERESGpqqlhbWz/yr1NdeOzC7lEycuRIOXz4sOzatUszfdiwYer/7du3lyZNmkj37t3l9OnTD+WX0UZERKj/d+jQQYKDg6V58+aycuXK+x5Cf5QvvvhCIiIiNN+r9ai9To+bsrIy6d+/vwCQBQsWaOa9/fbb6v8dOnQQOzs7GT58uCQmJj6U95R87bXX1P/bt28vHTp0kFatWsn27dule/fuD7BnD4/H7jCmm5ubWFtb1xjtl5OTI56eng+oVzWNGjVKvv/+e9m2bdsdv4E3ODhYREROnTolIiKenp61rp9l3u3aODk53fcAcnFxkdatW8upU6fE09NTSktLJT8/v0Zf7tRXy7zbtfkj1uf8+fPy448/ypAhQ27b7lF7nSx9uN3fiqenp+Tm5mrml5eXS15eXp28fvfrb9ISdOfPn5ctW7bc8XvdgoODpby8XM6dO3fb/lrm3a7NH/E507JlS3Fzc9O81x7F16kuPXZhZ2dnJ0899ZSkpKSoaZWVlZKSkiIhISEPsGdVAMioUaNk9erVsnXr1hqHFWpz4MABERFp0qSJiIiEhITIoUOHNG9uyx90mzZtVJvqvwNLmz/id3D9+nU5ffq0NGnSRJ566imxtbXV9OXEiRNy4cIF1ZeHfX0WL14s7u7uEhkZedt2j9rr1KJFC/H09NQ8v9lslrS0NM1rk5+fL+np6arN1q1bpbKyUoV7SEiI7NixQ8rKyjTr4O/vL66urqrNH7WelqA7efKk/Pjjj9KoUaM7PubAgQNiZWWlDgU+bOt0s//85z9y9epVzXvtUXud6tyDHiHzIKxYsQJGoxFLlizB0aNHMWzYMLi4uGhGxT0osbGxcHZ2xvbt2zXDiAsLCwEAp06dwowZM7Bv3z6cPXsWa9euRcuWLdG1a1e1DMuQ9p49e+LAgQPYtGkTGjduXOuQ9ri4OBw7dgzz58+/b0P1x40bh+3bt+Ps2bP4+eefERYWBjc3N+Tm5gKouvTAx8cHW7duxb59+xASEoKQkJCHdn2qq6iogI+PD+Lj4zXTH5XXqaCgABkZGcjIyICIYM6cOcjIyFAjE5OSkuDi4oK1a9fi4MGD6NOnT62XHjz55JNIS0vDrl278MQTT2iGtOfn58PDwwMDBgzA4cOHsWLFCjg6OtYY0m5jY4MPPvgAx44dw7Rp0/7rIe23W6fS0lL07t0bzZo1w4EDBzR/Y5ZRiLt378bcuXNx4MABnD59Gv/617/QuHFjDBw48KFcp4KCAowfPx6pqak4e/YsfvzxR3Tq1AlPPPEEiouL1TIettfpj/ZYhh0AzJs3Dz4+PrCzs8PTTz+NPXv2POguAagaVlxbLV68GABw4cIFdO3aFQ0bNoTRaISfnx/i4uI0128BwLlz5xAREQEHBwe4ublh3LhxKCsr07TZtm0bAgMDYWdnh5YtW6rnqGuvvvoqmjRpAjs7OzRt2hSvvvoqTp06peYXFRXh73//O1xdXeHo6Ih+/frh0qVLD+36VPfDDz9ARHDixAnN9Eflddq2bVut77dBgwYBqLr8YMqUKfDw8IDRaET37t1rrOvVq1cRFRWF+vXrw8nJCTExMSgoKNC0yczMRGhoKIxGI5o2bYqkpKQafVm5ciVat24NOzs7tG3bFuvXr6/zdTp79uwt/8Ys10emp6cjODgYzs7OsLe3x5/+9Ce89957muB4mNapsLAQPXv2ROPGjWFra4vmzZtj6NChNTbeH7bX6Y/G77MjIiLde+zO2RER0eOHYUdERLrHsCMiIt1j2BERke4x7IiISPcYdkREpHsMOyIi0j2GHRER6R7DjoiIdI9hR0REusewIyIi3ft/fgM6ZbYz09wAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the array\n",
    "plt.imshow(canvas[1], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1., -1.],\n",
       "       [-1., -1., -1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.ones((2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying a new geodataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "tile_path = Path('/mnt/data2/vaschetti_data/maxar/Gambia-flooding-8-11-2022/pre/10300100CFC9A500/033133031233.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = geoDatasets.MxrSingleTile(str(tile_path))\n",
    "sampler = samplers.WholeTifGridGeoSampler(dataset, batch_size=1, size= 1000, stride=1000)\n",
    "dataloader = DataLoader(dataset , batch_sampler=sampler, collate_fn=stack_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17408, 17408)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samplers_utils.tile_sizes(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 18)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler.get_rows_cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = np.zeros(samplers_utils.tile_sizes(dataset) +  (3,) , dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17408, 17408, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canvas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=4\n",
    "np.arange(len(sampler)).reshape((-1, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24, 25, 26])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=3\n",
    "batch_ix = 8\n",
    "img_ixs = np.arange(len(sampler)).reshape((-1, batch_size))[batch_ix]\n",
    "img_ixs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows, cols = sampler.get_rows_cols()\n",
    "img_ix = 20\n",
    "rows_changed = img_ix // cols\n",
    "cols_changed = img_ix % cols\n",
    "rows_changed, cols_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_ix = 18\n",
      "row, cols changed (1, 0)\n",
      "base = 0\n",
      "2000\n",
      "(15407, 16407) (0, 1000)\n"
     ]
    }
   ],
   "source": [
    "size = 1000\n",
    "stride = 1000\n",
    "batch_size = 4\n",
    "rows, cols = sampler.get_rows_cols()\n",
    "\n",
    "canvas = np.zeros(samplers_utils.tile_sizes(dataset) +  (2,) , dtype=np.uint8)\n",
    "\n",
    "inv_base = (canvas.shape[0] - 1) - size #dim 0, top left corner of the first patch\n",
    "base = 0 #dim 1, top left corner of the first patch\n",
    "\n",
    "batch_ix = 0\n",
    "img_ixs = np.arange(len(sampler)).reshape((-1, batch_size))[batch_ix]\n",
    "#img_ix = img_ixs[0]\n",
    "img_ix = 18\n",
    "print(f'{img_ix = }')\n",
    "\n",
    "rows_changed = img_ix // cols\n",
    "cols_changed = img_ix % cols\n",
    "print(f'row, cols changed {rows_changed, cols_changed}')\n",
    "\n",
    "base = (stride * cols_changed)\n",
    "print(f'{base = }')\n",
    "\n",
    "inv_base = (canvas.shape[0] - 1 - size) - (stride * rows_changed)\n",
    "print(f'{(canvas.shape[0]-1)-inv_base}')\n",
    "\n",
    "print((inv_base, inv_base + size) , (base, base + size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 7, 1, 1],\n",
       "        [1, 1, 1, 1, 1]],\n",
       "\n",
       "       [[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 7, 1, 1],\n",
       "        [1, 1, 1, 1, 1]]], dtype=uint8)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.ones((2, 5, 5), dtype=np.uint8)\n",
    "res[:, 3,2] = 7\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_base = canvas.shape[0]-1\n",
    "base = 0 \n",
    "size= 1000\n",
    "#deve tutto basarsi sull'indice di batch e batch size\n",
    "batch_size=4\n",
    "batch_ix = 0\n",
    "img_ixs = np.arange(len(sampler)).reshape((-1, batch_size))[batch_ix]\n",
    "#ora tutto deve basarsi su img_ixs\n",
    "\n",
    "\n",
    "#cambia \n",
    "#cambia riga ogni volta che aumente il numero\n",
    "\n",
    "#ogni volta che cambia riga inv_base -=  size\n",
    "#ogni volta che cambia colonna base += size, quando arrivo a fine riga deve resettarsi\n",
    "canvas[inv_base-size : inv_base,\n",
    "       base: base+size,\n",
    "       0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_counter = 0\n",
    "x_ = 0\n",
    "y_pxl = 0\n",
    "\n",
    "for i, batch in enumerate(dataloader):\n",
    "    if i%18 == 0:\n",
    "        x_pxl = 0\n",
    "        y_pxl += 1000\n",
    "    \n",
    "    x_pxl += 1000\n",
    "    print(i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(dataloader):\n",
    "    if i%30 != 0:\n",
    "        continue\n",
    "    image_tensor = batch['image'][0]\n",
    "    image = image_tensor.permute(1, 2, 0).numpy().astype('uint8')\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = geoDatasets.MxrSingleTile(str(tile_path))\n",
    "sampler = samplers.MyBatchGridGeoSampler(dataset, batch_size=1, size= 1000, stride=1000)\n",
    "dataloader = DataLoader(dataset , batch_sampler=sampler, collate_fn=stack_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for i, batch in enumerate(dataloader):\n",
    "    if i%30 != 0:\n",
    "        continue\n",
    "    image_tensor = batch['image'][0]\n",
    "    image = image_tensor.permute(1, 2, 0).numpy().astype('uint8')\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor = element['image'][15]\n",
    "image = image_tensor.permute(1, 2, 0).numpy().astype('uint8')\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of useful code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_final_mask = np.greater_equal(all_masks_b, 0).any(axis=1)\n",
    "np_final_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_functions.plotting_utils import show_mask\n",
    "import matplotlib.patches as patches\n",
    "    \n",
    "def plot_w_wo_masks_ESAM(img, masks, building_boxes = None, rgb_colors = [[117, 255, 61], [164, 99, 214], [80, 137, 199]] , random_color = False):\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.imshow(img)\n",
    "\n",
    "    ax2 = fig.add_subplot(1, 2, 2, sharex=ax1, sharey=ax1)\n",
    "    ax2.imshow(img)\n",
    "    if masks.ndim == 2:\n",
    "        masks = masks[np.newaxis, ...]\n",
    "    for i, mask in enumerate(masks):\n",
    "        show_mask(mask, ax2, rgb_color=rgb_colors[i] , random_color = random_color)\n",
    "    if building_boxes is not None:\n",
    "        for box in building_boxes:\n",
    "            x0, y0 = box[0], box[1]\n",
    "            w, h = box[2] - box[0], box[3] - box[1]\n",
    "            rect = patches.Rectangle((x0, y0), w, h, linewidth=1, edgecolor='r', facecolor='none')            \n",
    "            ax2.add_patch(rect)\n",
    "    \n",
    "    ax2.set_xlim([0, img.shape[1]])\n",
    "    ax2.set_ylim([img.shape[0], 0])\n",
    "\n",
    "    ax1.axis('off')\n",
    "    ax2.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 3\n",
    "plot_w_wo_masks_ESAM(img_b[ix], pad_mask_b[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 3\n",
    "plot_w_wo_masks_ESAM(img_b[ix], building_mask_b[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 9\n",
    "all_mask_no_overlap = segment.rmv_mask_overlap(np.stack((tree_mask_b[ix], building_mask_b[ix])))\n",
    "plot_w_wo_masks_ESAM(img_b[ix], all_mask_no_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_b_no_overlap = segment.rmv_mask_b_overlap(np.stack((tree_mask_b, building_mask_b), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 9\n",
    "plot_w_wo_masks_ESAM(img_b[ix], mask_b_no_overlap[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 1\n",
    "plot_w_wo_masks_ESAM(img_b[ix], np.stack((tree_mask_b[ix], building_mask_b[ix])), random_color=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmv_mask_overlap(overlapping_masks: np.array):\n",
    "    disjoined_masks = np.copy(overlapping_masks)\n",
    "    for i in range(overlapping_masks.shape[0] - 1):\n",
    "        sum_mask = np.sum(overlapping_masks[i:], axis=0)\n",
    "        disjoined_masks[i] = np.where(sum_mask > 1, False, overlapping_masks[i])\n",
    "\n",
    "    return disjoined_masks\n",
    "\n",
    "rmv_mask_overlap(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmv_mask_overlap(overlapping_masks: np.array):\n",
    "    for i in range(overlapping_masks.shape[0] - 1, 0, -1):\n",
    "        sum_mask = overlapping_masks[i-1] + overlapping_masks[i]\n",
    "        overlapping_masks[i]\n",
    "\n",
    "        print(i)\n",
    "\n",
    "    #return disjoined_masks\n",
    "\n",
    "rmv_mask_overlap(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "single_img_np = img_b[0]\n",
    "print(single_img_np.shape)\n",
    "a  = transforms.ToTensor()(single_img_np)\n",
    "single_img_tsr = original_img[0]\n",
    "b = single_img_tsr.div(255)\n",
    "torch.equal(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(original_img.div(255)[0], b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_img_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_img_tsr = original_img[0]\n",
    "single_img_tsr.div(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.from_numpy(single_img_np.transpose((2, 0, 1))).contiguous()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transforms.ToTensor()(original_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "with rasterio.open('/mnt/data2/vaschetti_data/maxar/Indonesia-Earthquake22/post/10300100DD6AE200/300020121231.tif') as src:\n",
    "    print(src.profile)\n",
    "    print(src.transform * (0,0))\n",
    "    print(type(src.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.tensor([torch.tensor([1,23]), torch.tensor([1,23])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[2,3,5,6]]*5)\n",
    "print('a', a.shape)\n",
    "b = np.expand_dims(a, 0)\n",
    "print('b', b.shape)\n",
    "b.reshape(-1,2,2).shape\n",
    "lbs = np.array([[2,3]]*a.shape[0]) #(query_img_x, 2)\n",
    "print('lbs', lbs.shape)\n",
    "\n",
    "lbs_pad_value = 0\n",
    "pad_len = 3\n",
    "pad_width = ((0,pad_len),(0, 0))\n",
    "padded_lbs = np.pad(lbs, pad_width, constant_values = lbs_pad_value)\n",
    "print('padded_lbs', padded_lbs.shape)\n",
    "\n",
    "#\n",
    "\n",
    "#np.expand_dims(np.array([[2,3]]*89), 0).reshape(-1,2,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_detect = 0\n",
    "for tree_detec, build_detec in zip(tree_boxes_b, building_boxes_b):\n",
    "    tree_build_detect = np.concatenate((tree_detec, build_detec))\n",
    "    print(tree_build_detect.shape)\n",
    "    if tree_build_detect.shape[0] > max_detect:\n",
    "        max_detect = tree_build_detect.shape[0]\n",
    "print(max_detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_build_detect[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes4FSam[9][-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_boxes_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_boxes_b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pad_len = max_detect - building_boxes_b[0].shape[0]\n",
    "pad_len = 4\n",
    "pad_width = ((0,pad_len),(0, 0))\n",
    "np.pad(building_boxes_b[0], pad_width, constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3],[4,5,6]])\n",
    "b = [a]\n",
    "np.array(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_width = ((0,1),(0, 0))\n",
    "pad_width = (1,1)\n",
    "pad_value = (1,2)\n",
    "np.pad(a, pad_width, constant_values = pad_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_width = (0, 2)\n",
    "pad_value = [0,0,0,0]\n",
    "np.pad(building_boxes_b[0], pad_width, constant_values=pad_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([4,5,6])\n",
    "np.concatenate((a,b))\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_boxes_b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_boxes_b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_functions.plotting_utils import show_mask, show_Linestrings, show_points, show_box, plot_comparison\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 7))\n",
    "ix = 8\n",
    "ax.imshow(img_b[ix])\n",
    "#show_box(tree_boxes_b[ix].tolist(), ax, color='b')\n",
    "show_box(building_boxes_b[ix], ax, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_functions.plotting_utils import show_mask, show_Linestrings, show_points, show_box, plot_comparison\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 7))\n",
    "ix = 9\n",
    "ax.imshow(img_b[ix])\n",
    "show_box(tree_boxes_b[ix].tolist(), ax, color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from my_functions import geoDatasets\n",
    "from my_functions.samplers import MyGridGeoSampler, MyBatchGridGeoSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchgeo.datasets import stack_samples, unbind_samples\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def segment_tile(self, tile_path):\n",
    "    batch_size = 4\n",
    "    dataset = geoDatasets.Maxar(str(tile_path))\n",
    "    sampler = MyBatchGridGeoSampler(dataset, batch_size=batch_size, size=100, stride=100)\n",
    "    print(len(sampler))\n",
    "    dataloader = DataLoader(dataset , batch_sampler=sampler, collate_fn=stack_samples)\n",
    "    print(len(dataloader))\n",
    "    print(dataset.res)\n",
    "    for batch in tqdm(dataloader):\n",
    "        #print(batch.keys())\n",
    "        #samples_list = unbind_samples(batch)\n",
    "        #print(samples_list)\n",
    "        #img_batch = batch['image']\n",
    "        #print(type(img_batch))\n",
    "        \n",
    "        #Le immagini sono già RGB\n",
    "        img_b = batch['image'].permute(0,2,3,1).numpy().astype('uint8')\n",
    "        #fig, axs = plt.subplots(1, batch_size, figsize=(30, 30))\n",
    "        #for i in range(batch_size):\n",
    "        #    axs[i].imshow(img_b[i])\n",
    "        #print(img_b.shape)\n",
    "        break\n",
    "    return img_b\n",
    "\n",
    "img_b = segment_tile(evento, m0.tiles_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0.dataset_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from my_functions import segment\n",
    "from groundingdino.util.inference import predict as GD_predict\n",
    "from groundingdino.util.inference import load_model as GD_load_model\n",
    "\n",
    "def get_gdino_boxes(img_batch: np.array,\n",
    "                    GDINO_model,\n",
    "                    TEXT_PROMPT,\n",
    "                    BOX_TRESHOLD,\n",
    "                    TEXT_TRESHOLD,\n",
    "                    dataset_res,\n",
    "                    max_area_mt2 =3000):\n",
    "    all_tree_boxes4Sam = []\n",
    "    for img in img_batch:\n",
    "        image_transformed = segment.dino_img_load(img)\n",
    "        tree_boxes, logits, phrases = GD_predict(GDINO_model, image_transformed, TEXT_PROMPT, BOX_TRESHOLD, TEXT_TRESHOLD)\n",
    "        tree_boxes4Sam = []\n",
    "        if len(tree_boxes) != 0:\n",
    "            sample_size = image_transformed.shape[-1]\n",
    "            keep_ix_tree_boxes = segment.filter_on_box_area_mt2(tree_boxes, sample_size, dataset_res, max_area_mt2 = max_area_mt2)\n",
    "            tree_boxes4Sam = segment.GDboxes2SamBoxes(tree_boxes[keep_ix_tree_boxes], sample_size)\n",
    "            all_tree_boxes4Sam.append(tree_boxes4Sam)\n",
    "    return all_tree_boxes4Sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDINO_root =\"/home/vaschetti/maxarSrc/models/GDINO\"\n",
    "CONFIG_PATH = os.path.join(GDINO_root, \"GroundingDINO_SwinT_OGC.py\")\n",
    "WEIGHTS_PATH = os.path.join(GDINO_root, \"groundingdino_swint_ogc.pth\")\n",
    "GDINO_model = GD_load_model(CONFIG_PATH, WEIGHTS_PATH, device = 'cuda')\n",
    "TEXT_PROMPT = 'green tree' #'house' or 'tree' or 'green tree'\n",
    "BOX_TRESHOLD = 0.15\n",
    "TEXT_TRESHOLD = 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_res = 0.30517578125\n",
    "get_gdino_boxes(img_b, GDINO_model, TEXT_PROMPT, BOX_TRESHOLD, TEXT_TRESHOLD, dataset_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import groundingdino.datasets.transforms as T\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "def batch_GD_img_load(batch_np_img_rgb: np.array)-> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Transform the image from np.array to torch.Tensor and normalize it.\n",
    "    \"\"\"\n",
    "    transform = T.Compose(\n",
    "        [\n",
    "            T.RandomResize([800], max_size=1333),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "    for i, np_img_rgb in enumerate(batch_np_img_rgb):\n",
    "        image_pillow = Image.fromarray(np_img_rgb)\n",
    "        image_transformed, _ = transform(image_pillow, None)\n",
    "        if i == 0:\n",
    "            batch_images_transformed = image_transformed.unsqueeze(0)\n",
    "        else:\n",
    "            batch_images_transformed = torch.cat((batch_images_transformed, image_transformed.unsqueeze(0)), dim=0)\n",
    "    return batch_images_transformed\n",
    "\n",
    "def dino_img_load(np_img_rgb: np.array)-> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Transform the image from np.array to torch.Tensor and normalize it.\n",
    "    \"\"\"\n",
    "    transform = T.Compose(\n",
    "        [\n",
    "            T.RandomResize([800], max_size=1333),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "    image_pillow = Image.fromarray(np_img_rgb)\n",
    "    image_transformed, _ = transform(image_pillow, None)\n",
    "    return image_transformed\n",
    "\n",
    "def load_image(image_path):\n",
    "    # load image\n",
    "    image_pil = Image.open(image_path).convert(\"RGB\")  # load image\n",
    "    print(image_pil.getbands())\n",
    "\n",
    "    transform = T.Compose(\n",
    "        [\n",
    "            T.RandomResize([800], max_size=1333),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "    image, _ = transform(image_pil, None)  # 3, h, w\n",
    "    return image_pil, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, image_transformed = load_image('/home/vaschetti/maxarSrc/exampleData/10300100C2D81700-visual_small.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/vaschetti/maxarSrc/exampleData/10300100C2D81700-visual.tif'\n",
    "image_pil, image = load_image(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pil.getbands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Image.open(img_path).convert(\"RGB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image.permute(1,2,0).numpy().astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maxarSrc",
   "language": "python",
   "name": "maxarsrc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
